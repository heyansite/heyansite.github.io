<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>HDFS | Yan&#39;s Blog Home</title>
    <meta name="description" content="Personal blog site">
    
    
    <link rel="preload" href="/assets/css/0.styles.ad4900be.css" as="style"><link rel="preload" href="/assets/js/app.251ed5d9.js" as="script"><link rel="preload" href="/assets/js/2.858e58ff.js" as="script"><link rel="preload" href="/assets/js/38.61d0edc2.js" as="script"><link rel="prefetch" href="/assets/js/10.5dcc1f52.js"><link rel="prefetch" href="/assets/js/100.c5640ec8.js"><link rel="prefetch" href="/assets/js/101.323d4ccf.js"><link rel="prefetch" href="/assets/js/102.d94a08aa.js"><link rel="prefetch" href="/assets/js/103.678e430d.js"><link rel="prefetch" href="/assets/js/104.b400bd3a.js"><link rel="prefetch" href="/assets/js/105.b6229a45.js"><link rel="prefetch" href="/assets/js/106.3ee7df20.js"><link rel="prefetch" href="/assets/js/107.4a958290.js"><link rel="prefetch" href="/assets/js/108.3ea2d0fb.js"><link rel="prefetch" href="/assets/js/109.e1eb969c.js"><link rel="prefetch" href="/assets/js/11.ff52cad9.js"><link rel="prefetch" href="/assets/js/110.a6e6e273.js"><link rel="prefetch" href="/assets/js/111.a172e2a2.js"><link rel="prefetch" href="/assets/js/112.dfc2a86d.js"><link rel="prefetch" href="/assets/js/113.6df6d874.js"><link rel="prefetch" href="/assets/js/114.302b8495.js"><link rel="prefetch" href="/assets/js/115.8651aa48.js"><link rel="prefetch" href="/assets/js/116.9e1f9a0b.js"><link rel="prefetch" href="/assets/js/117.9a74f4ce.js"><link rel="prefetch" href="/assets/js/118.121a666c.js"><link rel="prefetch" href="/assets/js/119.ca6819f9.js"><link rel="prefetch" href="/assets/js/12.b633635b.js"><link rel="prefetch" href="/assets/js/120.efe65d91.js"><link rel="prefetch" href="/assets/js/121.72958c2e.js"><link rel="prefetch" href="/assets/js/122.72c5fb33.js"><link rel="prefetch" href="/assets/js/123.e94917c1.js"><link rel="prefetch" href="/assets/js/124.11cc8c85.js"><link rel="prefetch" href="/assets/js/125.437fd863.js"><link rel="prefetch" href="/assets/js/126.207eaa74.js"><link rel="prefetch" href="/assets/js/127.125a30c1.js"><link rel="prefetch" href="/assets/js/128.1af89ad7.js"><link rel="prefetch" href="/assets/js/129.269e955a.js"><link rel="prefetch" href="/assets/js/13.4bfed5d6.js"><link rel="prefetch" href="/assets/js/130.3d2d293b.js"><link rel="prefetch" href="/assets/js/131.59e95e31.js"><link rel="prefetch" href="/assets/js/132.46b0ce06.js"><link rel="prefetch" href="/assets/js/133.f24ba32d.js"><link rel="prefetch" href="/assets/js/134.c8fe20d2.js"><link rel="prefetch" href="/assets/js/135.c7a5061f.js"><link rel="prefetch" href="/assets/js/136.b618e419.js"><link rel="prefetch" href="/assets/js/137.940c57e9.js"><link rel="prefetch" href="/assets/js/138.d59a4686.js"><link rel="prefetch" href="/assets/js/139.b2f4f7fd.js"><link rel="prefetch" href="/assets/js/14.49597bec.js"><link rel="prefetch" href="/assets/js/140.44b06552.js"><link rel="prefetch" href="/assets/js/141.f6a6d207.js"><link rel="prefetch" href="/assets/js/142.c86df684.js"><link rel="prefetch" href="/assets/js/143.5fd6fd83.js"><link rel="prefetch" href="/assets/js/144.c803a4cd.js"><link rel="prefetch" href="/assets/js/145.103c81ef.js"><link rel="prefetch" href="/assets/js/146.cd714a4a.js"><link rel="prefetch" href="/assets/js/147.df610887.js"><link rel="prefetch" href="/assets/js/148.3e704f1c.js"><link rel="prefetch" href="/assets/js/149.9291cd1d.js"><link rel="prefetch" href="/assets/js/15.16f4b9c1.js"><link rel="prefetch" href="/assets/js/150.6bf9657f.js"><link rel="prefetch" href="/assets/js/151.5ba13642.js"><link rel="prefetch" href="/assets/js/152.3f4f4ca8.js"><link rel="prefetch" href="/assets/js/153.b93c66a6.js"><link rel="prefetch" href="/assets/js/154.a398d903.js"><link rel="prefetch" href="/assets/js/155.63f86958.js"><link rel="prefetch" href="/assets/js/156.54044f43.js"><link rel="prefetch" href="/assets/js/157.f0e2bcb3.js"><link rel="prefetch" href="/assets/js/158.5b91c0e7.js"><link rel="prefetch" href="/assets/js/159.ab5444bc.js"><link rel="prefetch" href="/assets/js/16.c616e2b6.js"><link rel="prefetch" href="/assets/js/160.2530c91d.js"><link rel="prefetch" href="/assets/js/161.1df05a75.js"><link rel="prefetch" href="/assets/js/162.dad7fc47.js"><link rel="prefetch" href="/assets/js/163.b2d75a8a.js"><link rel="prefetch" href="/assets/js/164.4b49bb3c.js"><link rel="prefetch" href="/assets/js/165.ac1b34cb.js"><link rel="prefetch" href="/assets/js/166.00826470.js"><link rel="prefetch" href="/assets/js/167.e152507a.js"><link rel="prefetch" href="/assets/js/168.e668c315.js"><link rel="prefetch" href="/assets/js/169.c0832495.js"><link rel="prefetch" href="/assets/js/17.c15fd290.js"><link rel="prefetch" href="/assets/js/170.265153fd.js"><link rel="prefetch" href="/assets/js/171.362c431d.js"><link rel="prefetch" href="/assets/js/172.5e1589e8.js"><link rel="prefetch" href="/assets/js/173.7d1fef7b.js"><link rel="prefetch" href="/assets/js/174.e7293e4a.js"><link rel="prefetch" href="/assets/js/175.b28bdea7.js"><link rel="prefetch" href="/assets/js/176.c2d7977b.js"><link rel="prefetch" href="/assets/js/177.377eb895.js"><link rel="prefetch" href="/assets/js/178.1fa90333.js"><link rel="prefetch" href="/assets/js/179.68c5de48.js"><link rel="prefetch" href="/assets/js/18.db4a03ec.js"><link rel="prefetch" href="/assets/js/180.acb281b9.js"><link rel="prefetch" href="/assets/js/181.2be18ec9.js"><link rel="prefetch" href="/assets/js/182.bc60d6b6.js"><link rel="prefetch" href="/assets/js/183.f2919036.js"><link rel="prefetch" href="/assets/js/184.b38aec29.js"><link rel="prefetch" href="/assets/js/185.9a669ac8.js"><link rel="prefetch" href="/assets/js/186.e779fe45.js"><link rel="prefetch" href="/assets/js/187.468bfbe8.js"><link rel="prefetch" href="/assets/js/188.20d2e93c.js"><link rel="prefetch" href="/assets/js/189.42db30b7.js"><link rel="prefetch" href="/assets/js/19.d3b9b0a8.js"><link rel="prefetch" href="/assets/js/190.dea239ec.js"><link rel="prefetch" href="/assets/js/191.ccf9ae83.js"><link rel="prefetch" href="/assets/js/192.e2d30cca.js"><link rel="prefetch" href="/assets/js/193.62867c3e.js"><link rel="prefetch" href="/assets/js/194.13629983.js"><link rel="prefetch" href="/assets/js/195.4b68f3a0.js"><link rel="prefetch" href="/assets/js/196.ff59e8f6.js"><link rel="prefetch" href="/assets/js/197.15e020f7.js"><link rel="prefetch" href="/assets/js/198.4ea70ef4.js"><link rel="prefetch" href="/assets/js/199.56f0c110.js"><link rel="prefetch" href="/assets/js/20.c35dcf39.js"><link rel="prefetch" href="/assets/js/200.78dd9f28.js"><link rel="prefetch" href="/assets/js/201.91a68593.js"><link rel="prefetch" href="/assets/js/202.8a14b96a.js"><link rel="prefetch" href="/assets/js/203.a23a704a.js"><link rel="prefetch" href="/assets/js/204.dab38ee5.js"><link rel="prefetch" href="/assets/js/21.e43c696c.js"><link rel="prefetch" href="/assets/js/22.393983f9.js"><link rel="prefetch" href="/assets/js/23.e302c532.js"><link rel="prefetch" href="/assets/js/24.f4df4e7f.js"><link rel="prefetch" href="/assets/js/25.85aee522.js"><link rel="prefetch" href="/assets/js/26.f3d4bc2d.js"><link rel="prefetch" href="/assets/js/27.03f420d3.js"><link rel="prefetch" href="/assets/js/28.c8ad758a.js"><link rel="prefetch" href="/assets/js/29.acb65439.js"><link rel="prefetch" href="/assets/js/3.753236a7.js"><link rel="prefetch" href="/assets/js/30.fc1f5f5c.js"><link rel="prefetch" href="/assets/js/31.77e58103.js"><link rel="prefetch" href="/assets/js/32.5ef2f040.js"><link rel="prefetch" href="/assets/js/33.fc4584e7.js"><link rel="prefetch" href="/assets/js/34.71ca5ff9.js"><link rel="prefetch" href="/assets/js/35.bd5aae58.js"><link rel="prefetch" href="/assets/js/36.124f8c76.js"><link rel="prefetch" href="/assets/js/37.901c9e05.js"><link rel="prefetch" href="/assets/js/39.7921a116.js"><link rel="prefetch" href="/assets/js/4.fdb5e485.js"><link rel="prefetch" href="/assets/js/40.b389d659.js"><link rel="prefetch" href="/assets/js/41.0a58c3f1.js"><link rel="prefetch" href="/assets/js/42.e7961d9e.js"><link rel="prefetch" href="/assets/js/43.af113228.js"><link rel="prefetch" href="/assets/js/44.7560b6a3.js"><link rel="prefetch" href="/assets/js/45.4291ebfa.js"><link rel="prefetch" href="/assets/js/46.65a6b698.js"><link rel="prefetch" href="/assets/js/47.2eb4574c.js"><link rel="prefetch" href="/assets/js/48.b0c68533.js"><link rel="prefetch" href="/assets/js/49.020f0482.js"><link rel="prefetch" href="/assets/js/5.29130c00.js"><link rel="prefetch" href="/assets/js/50.b7cb1a11.js"><link rel="prefetch" href="/assets/js/51.efe2b5f7.js"><link rel="prefetch" href="/assets/js/52.a96f1076.js"><link rel="prefetch" href="/assets/js/53.95f7bac7.js"><link rel="prefetch" href="/assets/js/54.476274a8.js"><link rel="prefetch" href="/assets/js/55.41919574.js"><link rel="prefetch" href="/assets/js/56.beb74e07.js"><link rel="prefetch" href="/assets/js/57.705bc19e.js"><link rel="prefetch" href="/assets/js/58.f5fd656b.js"><link rel="prefetch" href="/assets/js/59.04bd0a11.js"><link rel="prefetch" href="/assets/js/6.192ba4c2.js"><link rel="prefetch" href="/assets/js/60.df29a101.js"><link rel="prefetch" href="/assets/js/61.061546fa.js"><link rel="prefetch" href="/assets/js/62.b733d1a1.js"><link rel="prefetch" href="/assets/js/63.926cae9b.js"><link rel="prefetch" href="/assets/js/64.54761bdd.js"><link rel="prefetch" href="/assets/js/65.f2c05d04.js"><link rel="prefetch" href="/assets/js/66.c50ec6bd.js"><link rel="prefetch" href="/assets/js/67.3f1e9d42.js"><link rel="prefetch" href="/assets/js/68.e6d72026.js"><link rel="prefetch" href="/assets/js/69.2de511ae.js"><link rel="prefetch" href="/assets/js/7.162225cc.js"><link rel="prefetch" href="/assets/js/70.65ac284e.js"><link rel="prefetch" href="/assets/js/71.a21ab478.js"><link rel="prefetch" href="/assets/js/72.1da0eaf9.js"><link rel="prefetch" href="/assets/js/73.fcfaf581.js"><link rel="prefetch" href="/assets/js/74.8edbd39c.js"><link rel="prefetch" href="/assets/js/75.70f5ea97.js"><link rel="prefetch" href="/assets/js/76.557c0bb2.js"><link rel="prefetch" href="/assets/js/77.9ce82f4b.js"><link rel="prefetch" href="/assets/js/78.0d809ae3.js"><link rel="prefetch" href="/assets/js/79.a9b07316.js"><link rel="prefetch" href="/assets/js/8.a12bb62b.js"><link rel="prefetch" href="/assets/js/80.fdc72255.js"><link rel="prefetch" href="/assets/js/81.beb8303a.js"><link rel="prefetch" href="/assets/js/82.0cb6ec59.js"><link rel="prefetch" href="/assets/js/83.0f3e946b.js"><link rel="prefetch" href="/assets/js/84.2e2f1d80.js"><link rel="prefetch" href="/assets/js/85.d850d4dd.js"><link rel="prefetch" href="/assets/js/86.32d87d56.js"><link rel="prefetch" href="/assets/js/87.5f97a4f6.js"><link rel="prefetch" href="/assets/js/88.f5b0bbdb.js"><link rel="prefetch" href="/assets/js/89.9f9150f5.js"><link rel="prefetch" href="/assets/js/9.0d992d03.js"><link rel="prefetch" href="/assets/js/90.f69286ce.js"><link rel="prefetch" href="/assets/js/91.cd415cf2.js"><link rel="prefetch" href="/assets/js/92.30ee9be1.js"><link rel="prefetch" href="/assets/js/93.9fc6f609.js"><link rel="prefetch" href="/assets/js/94.3d6138bf.js"><link rel="prefetch" href="/assets/js/95.d6a20d18.js"><link rel="prefetch" href="/assets/js/96.afb03bd8.js"><link rel="prefetch" href="/assets/js/97.14206eba.js"><link rel="prefetch" href="/assets/js/98.0d5b3805.js"><link rel="prefetch" href="/assets/js/99.d81e6ba7.js">
    <link rel="stylesheet" href="/assets/css/0.styles.ad4900be.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">Yan's Blog Home</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">Blog Home</a></div><div class="nav-item"><a href="/index/" class="nav-link">Technical Blog Home</a></div><div class="nav-item"><a href="https://heyan.site:8003/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Other Blog Home
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div><div class="nav-item"><a href="/comments.html" class="nav-link">留言</a></div><div class="nav-item"><a href="http://heyan.site/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Site Home
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">Blog Home</a></div><div class="nav-item"><a href="/index/" class="nav-link">Technical Blog Home</a></div><div class="nav-item"><a href="https://heyan.site:8003/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Other Blog Home
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div><div class="nav-item"><a href="/comments.html" class="nav-link">留言</a></div><div class="nav-item"><a href="http://heyan.site/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Site Home
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>大数据和分布式系统</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>分布式系统理论</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>分布式协调服务</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>数据摄取 Layer</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>数据流 Layer</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>数据存储 Layer</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>数据处理 Layer</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>数据分析 Layer (OLAP)</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>分布式系统基础框架Hadoop</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/BigDataAndDistributedSystem/Hadoop/" class="sidebar-link">Hadoop</a></li><li><a href="/BigDataAndDistributedSystem/Hadoop/HadoopInstall.html" class="sidebar-link">Hadoop安装初体验</a></li><li><a href="/BigDataAndDistributedSystem/Hadoop/hdfs.html" class="active sidebar-link">HDFS</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/Hadoop/hdfs.html#基本概念" class="sidebar-link">基本概念</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/Hadoop/hdfs.html#hdfs设计目标" class="sidebar-link">HDFS设计目标</a></li></ul></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/Hadoop/hdfs.html#hdfs重要特性" class="sidebar-link">HDFS重要特性</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/Hadoop/hdfs.html#hdfs基本操作" class="sidebar-link">HDFS基本操作</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/Hadoop/hdfs.html#hdfs基本原理" class="sidebar-link">HDFS基本原理</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/Hadoop/hdfs.html#_1．-namenode概述" class="sidebar-link">1． NameNode概述</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/Hadoop/hdfs.html#_2．-datanode概述" class="sidebar-link">2． DataNode概述</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/Hadoop/hdfs.html#_3．-hdfs的工作机制" class="sidebar-link">3． HDFS的工作机制</a></li></ul></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/Hadoop/hdfs.html#hdfs的应用开发" class="sidebar-link">HDFS的应用开发</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/Hadoop/hdfs.html#hdfs的java-api操作" class="sidebar-link">HDFS的JAVA API操作</a></li></ul></li></ul></li><li><a href="/BigDataAndDistributedSystem/Hadoop/MapReduce.html" class="sidebar-link">MapReduce</a></li><li><a href="/BigDataAndDistributedSystem/Hadoop/MapReduce-sample.html" class="sidebar-link">MapReduce案例</a></li><li><a href="/BigDataAndDistributedSystem/Hadoop/hive.html" class="sidebar-link">Hive</a></li><li><a href="/BigDataAndDistributedSystem/Hadoop/hbase.html" class="sidebar-link">HBase</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Data Platform - Splunk</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Data Platform - ELK</span> <span class="arrow right"></span></p> <!----></section></li><li><a href="/index/" class="sidebar-link">&lt; 首页</a></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="hdfs"><a href="#hdfs" class="header-anchor">#</a> HDFS</h1> <div class="custom-block tip"><p class="custom-block-title">此文为转载 （通常一篇文章会参考多处，也会添加自己的理解，引用地址如有遗漏，请指出）</p> <ul><li>https://www.bilibili.com/video/av79967392?p=1</li> <li>https://blog.csdn.net/CoderBoom/article/details/84112476</li></ul></div> <br> <h2 id="基本概念"><a href="#基本概念" class="header-anchor">#</a> <strong>基本概念</strong></h2> <p>HDFS是Hadoop Distribute File System 的简称，意为：Hadoop分布式文件系统。是Hadoop核心组件之一，作为最底层的分布式存储服务而存在。</p> <p>分布式文件系统解决的问题就是大数据存储。它们是横跨在多台计算机上的存储系统。分布式文件系统在大数据时代有着广泛的应用前景，它们为存储和处理超大规模数据提供所需的扩展能力。</p> <h3 id="hdfs设计目标"><a href="#hdfs设计目标" class="header-anchor">#</a> <strong>HDFS设计目标</strong></h3> <ul><li>硬件故障是常态， HDFS将有成百上千的服务器组成，每一个组成部分都有可能出现故障。因此故障的检测和自动快速恢复是HDFS的核心架构目标。</li> <li>HDFS上的应用与一般的应用不同，它们主要是以流式读取数据。HDFS被设计成适合批量处理，而不是用户交互式的。相较于数据访问的反应时间，更注重数据访问的高吞吐量。</li> <li>典型的HDFS文件大小是GB到TB的级别。所以，HDFS被调整成支持大文件。它应该提供很高的聚合数据带宽，一个集群中支持数百个节点，一个集群中还应该支持千万级别的文件。</li> <li>大部分HDFS应用对文件要求的是write-one-read-many访问模型。一个文件一旦创建、写入、关闭之后就不需要修改了。这一假设简化了数据一致性问题，使高吞吐量的数据访问成为可能。</li> <li>移动计算的代价比之移动数据的代价低。一个应用请求的计算，离它操作的数据越近就越高效，这在数据达到海量级别的时候更是如此。将计算移动到数据附近，比之将数据移动到应用所在显然更好。</li> <li>在异构的硬件和软件平台上的可移植性。这将推动需要大数据集的应用更广泛地采用HDFS作为平台。</li></ul> <h2 id="hdfs重要特性"><a href="#hdfs重要特性" class="header-anchor">#</a> <strong>HDFS重要特性</strong></h2> <p>首先，它是一个文件系统，用于存储文件，通过统一的命名空间目录树来定位文件；<br>其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。</p> <ol><li><strong>master/slave架构</strong><br>HDFS采用master/slave架构。一般一个HDFS集群是有一个Namenode和一定数目的Datanode组成。Namenode是HDFS集群主节点，Datanode是HDFS集群从节点，两种角色各司其职，共同协调完成分布式的文件存储服务。</li> <li><strong>分块存储</strong><br>HDFS中的文件在物理上是分块存储（block）的，块的大小可以通过配置参数来规定，默认大小在hadoop2.x版本中是128M。</li> <li><strong>名字空间（NameSpace）</strong><br>HDFS支持传统的层次型文件组织结构。用户或者应用程序可以创建目录，然后将文件保存在这些目录里。文件系统名字空间的层次结构和大多数现有的文件系统类似：用户可以创建、删除、移动或重命名文件。<br>Namenode负责维护文件系统的名字空间，任何对文件系统名字空间或属性的修改都将被Namenode记录下来。<br>HDFS会给客户端提供一个统一的抽象目录树，客户端通过路径来访问文件，形如：hdfs://namenode:port/dir-a/dir-b/dir-c/file.data。</li> <li><strong>Namenode元数据管理</strong><br>我们把目录结构及文件分块位置信息叫做元数据。Namenode负责维护整个hdfs文件系统的目录树结构，以及每一个文件所对应的block块信息（block的id，及所在的datanode服务器）。</li> <li><strong>Datanode数据存储</strong><br>文件的各个block的具体存储管理由datanode节点承担。每一个block都可以在多个datanode上。Datanode需要定时向Namenode汇报自己持有的block信息。<br>存储多个副本（副本数量也可以通过参数设置dfs.replication，默认是3）。</li> <li><strong>副本机制</strong><br>为了容错，文件的所有block都会有副本。每个文件的block大小和副本系数都是可配置的。应用程序可以指定某个文件的副本数目。副本系数可以在文件创建的时候指定，也可以在之后改变。</li> <li><strong>一次写入，多次读出</strong><br>HDFS是设计成适应一次写入，多次读出的场景，且不支持文件的修改。<br>正因为如此，HDFS适合用来做大数据分析的底层存储服务，并不适合用来做.网盘等应用，因为，修改不方便，延迟大，网络开销大，成本太高。</li></ol> <blockquote><p>namenode作为hdfs的老大 , 管理着文件系统的全部元数据</p> <ul><li>目录树</li> <li>文件跟块对应信息</li> <li>datanode信息(dn是否存活 , 磁盘是否已满)</li></ul> <p>访问 : hdfs://namenode_ip:9000</p></blockquote> <p>模拟实现分布式文件系统图解:</p> <div style="display:flex;"><img src="/assets/img/hdfs-4.2c666232.jpg" alt="" align="left" style="display:block;"></div> <br> <h2 id="hdfs基本操作"><a href="#hdfs基本操作" class="header-anchor">#</a> <strong>HDFS基本操作</strong></h2> <p><strong>1． Shell 命令行客户端</strong></p> <p>Hadoop提供了文件系统的shell命令行客户端，使用方法如下：</p> <div class="language-sh line-numbers-mode"><pre class="language-sh"><code>hadoop  fs  <span class="token operator">&lt;</span>args<span class="token operator">&gt;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>文件系统shell包括与Hadoop分布式文件系统（HDFS）以及Hadoop支持的其他文件系统（如本地FS，HFTP FS，S3 FS等）直接交互的各种类似shell的命令。所有FS shell命令都将路径URI作为参数。<br>URI格式为scheme://authority/path。对于HDFS，该scheme是hdfs，对于本地FS，该scheme是file。scheme和authority是可选的。如果未指定，则使用配置中指定的默认方案。</p> <p>对于HDFS,命令示例如下：</p> <div class="language-sh line-numbers-mode"><pre class="language-sh"><code>hadoop fs -ls  hdfs://namenode:host/parent/child

hadoop fs -ls  /parent/child  <span class="token comment">#fs.defaultFS中有配置</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>对于本地文件系统，命令示例如下：</p> <div class="language-sh line-numbers-mode"><pre class="language-sh"><code>hadoop fs -ls file:///root/
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>如果使用的文件系统是HDFS，则使用hdfs dfs也是可以的，此时</p> <div class="language-sh line-numbers-mode"><pre class="language-sh"><code>hadoop fs <span class="token operator">&lt;</span>args<span class="token operator">&gt;</span> <span class="token operator">=</span> hdfs dfs <span class="token operator">&lt;</span>args<span class="token operator">&gt;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p><strong>2． 常用Shell 命令</strong></p> <div class="language-sh line-numbers-mode"><pre class="language-sh"><code><span class="token function">ls</span>
使用方法：hadoop fs -ls <span class="token punctuation">[</span>-h<span class="token punctuation">]</span> <span class="token punctuation">[</span>-R<span class="token punctuation">]</span> <span class="token operator">&lt;</span>args<span class="token operator">&gt;</span>
功能：显示文件、目录信息。
示例：hadoop fs -ls /user/hadoop/file1

<span class="token function">mkdir</span>
使用方法：hadoop fs -mkdir <span class="token punctuation">[</span>-p<span class="token punctuation">]</span> <span class="token operator">&lt;</span>paths<span class="token operator">&gt;</span>
功能：在hdfs上创建目录，-p表示会创建路径中的各级父目录。
示例：hadoop fs -mkdir –p /user/hadoop/dir1

put
使用方法：hadoop fs -put <span class="token punctuation">[</span>-f<span class="token punctuation">]</span> <span class="token punctuation">[</span>-p<span class="token punctuation">]</span> <span class="token punctuation">[</span> -<span class="token operator">|</span><span class="token operator">&lt;</span>localsrc<span class="token operator"><span class="token file-descriptor important">1</span>&gt;</span> <span class="token punctuation">..</span> <span class="token punctuation">]</span>. <span class="token operator">&lt;</span>dst<span class="token operator">&gt;</span>
功能：将单个src或多个srcs从本地文件系统复制到目标文件系统。
-p：保留访问和修改时间，所有权和权限。
-f：覆盖目的地（如果已经存在）
示例：hadoop fs -put -f localfile1 localfile2 /user/hadoop/hadoopdir

get
使用方法：hadoop fs -get <span class="token punctuation">[</span>-ignorecrc<span class="token punctuation">]</span> <span class="token punctuation">[</span>-crc<span class="token punctuation">]</span> <span class="token punctuation">[</span>-p<span class="token punctuation">]</span> <span class="token punctuation">[</span>-f<span class="token punctuation">]</span> <span class="token operator">&lt;</span>src<span class="token operator">&gt;</span> <span class="token operator">&lt;</span>localdst<span class="token operator">&gt;</span>
-ignorecrc：跳过对下载文件的CRC检查。
-crc：为下载的文件写CRC校验和。
功能：将文件复制到本地文件系统。
示例：hadoop fs -get hdfs://host:port/user/hadoop/file localfile

appendToFile
使用方法：hadoop fs -appendToFile <span class="token operator">&lt;</span>localsrc<span class="token operator">&gt;</span> <span class="token punctuation">..</span>. <span class="token operator">&lt;</span>dst<span class="token operator">&gt;</span>
功能：追加一个文件到已经存在的文件末尾
示例：hadoop fs -appendToFile localfile  /hadoop/hadoopfile

<span class="token function">cat</span>
使用方法：hadoop fs -cat <span class="token punctuation">[</span>-ignoreCrc<span class="token punctuation">]</span> URI <span class="token punctuation">[</span>URI <span class="token punctuation">..</span>.<span class="token punctuation">]</span>
功能：显示文件内容到stdout
示例：hadoop fs -cat /hadoop/hadoopfile

<span class="token function">tail</span>
使用方法：hadoop fs -tail <span class="token punctuation">[</span>-f<span class="token punctuation">]</span> URI
功能：将文件的最后一千字节内容显示到stdout。
-f选项将在文件增长时输出附加数据。
示例：hadoop fs -tail /hadoop/hadoopfile

<span class="token function">chgrp</span>
使用方法：hadoop fs -chgrp <span class="token punctuation">[</span>-R<span class="token punctuation">]</span> GROUP URI <span class="token punctuation">[</span>URI <span class="token punctuation">..</span>.<span class="token punctuation">]</span>
功能：更改文件组的关联。用户必须是文件的所有者，否则是超级用户。
-R将使改变在目录结构下递归进行。
示例：hadoop fs -chgrp othergroup /hadoop/hadoopfile

<span class="token function">chmod</span>
功能：改变文件的权限。使用-R将使改变在目录结构下递归进行。
示例：hadoop fs -chmod <span class="token number">666</span> /hadoop/hadoopfile

<span class="token function">chown</span>
功能：改变文件的拥有者。使用-R将使改变在目录结构下递归进行。
示例：hadoop fs -chown someuser:somegrp  /hadoop/hadoopfile

copyFromLocal
使用方法：hadoop fs -copyFromLocal <span class="token operator">&lt;</span>localsrc<span class="token operator">&gt;</span> URI
功能：从本地文件系统中拷贝文件到hdfs路径去
示例：hadoop fs -copyFromLocal /root/1.txt /

copyToLocal 
功能：从hdfs拷贝到本地
示例：hadoop fs -copyToLocal /aaa/jdk.tar.gz

<span class="token function">cp</span>      
功能：从hdfs的一个路径拷贝hdfs的另一个路径
示例： hadoop fs -cp /aaa/jdk.tar.gz /bbb/jdk.tar.gz.2

<span class="token function">mv</span>           
功能：在hdfs目录中移动文件
示例： hadoop fs -mv /aaa/jdk.tar.gz /

getmerge   
功能：合并下载多个文件
示例：比如hdfs的目录 /aaa/下有多个文件:log.1, log.2,log.3,<span class="token punctuation">..</span>.
hadoop fs -getmerge /aaa/log.*  ./log.sum

<span class="token function">rm</span>        
功能：删除指定的文件。只删除非空目录和文件。-r 递归删除。
示例：hadoop fs -rm -r /aaa/bbb/

<span class="token function">df</span>        
功能：统计文件系统的可用空间信息
示例：hadoop fs -df -h /

<span class="token function">du</span>
功能：显示目录中所有文件大小，当只指定一个文件时，显示此文件的大小。
示例：hadoop fs -du /user/hadoop/dir1

setrep        
功能：改变一个文件的副本系数。-R选项用于递归改变目录下所有文件的副本系数。
示例：hadoop fs -setrep -w <span class="token number">3</span> -R /user/hadoop/dir1
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br><span class="line-number">71</span><br><span class="line-number">72</span><br><span class="line-number">73</span><br><span class="line-number">74</span><br><span class="line-number">75</span><br><span class="line-number">76</span><br><span class="line-number">77</span><br><span class="line-number">78</span><br><span class="line-number">79</span><br><span class="line-number">80</span><br><span class="line-number">81</span><br><span class="line-number">82</span><br><span class="line-number">83</span><br><span class="line-number">84</span><br><span class="line-number">85</span><br><span class="line-number">86</span><br><span class="line-number">87</span><br><span class="line-number">88</span><br><span class="line-number">89</span><br><span class="line-number">90</span><br><span class="line-number">91</span><br></div></div><h2 id="hdfs基本原理"><a href="#hdfs基本原理" class="header-anchor">#</a> <strong>HDFS基本原理</strong></h2> <h3 id="_1．-namenode概述"><a href="#_1．-namenode概述" class="header-anchor">#</a> <strong>1． NameNode概述</strong></h3> <ol><li>NameNode是HDFS的核心。</li> <li>NameNode也称为Master。</li> <li>NameNode仅存储HDFS的元数据：文件系统中所有文件的目录树，并跟踪整个集群中的文件。</li> <li>NameNode不存储实际数据或数据集。数据本身实际存储在DataNodes中。</li> <li>NameNode知道HDFS中任何给定文件的块列表及其位置。使用此信息NameNode知道如何从块中构建文件。</li> <li>NameNode并不持久化存储每个文件中各个块所在的DataNode的位置信息，这些信息会在系统启动时从数据节点重建。</li> <li>NameNode对于HDFS至关重要，当NameNode关闭时，HDFS / Hadoop集群无法访问。</li> <li>NameNode是Hadoop集群中的单点故障。</li> <li>NameNode所在机器通常会配置有大量内存（RAM）。</li></ol> <br> <h3 id="_2．-datanode概述"><a href="#_2．-datanode概述" class="header-anchor">#</a> <strong>2． DataNode概述</strong></h3> <ol><li>DataNode负责将实际数据存储在HDFS中。</li> <li>DataNode也称为Slave。</li> <li>NameNode和DataNode会保持不断通信。</li> <li>DataNode启动时，它将自己发布到NameNode并汇报自己负责持有的块列表。</li> <li>当某个DataNode关闭时，它不会影响数据或群集的可用性。NameNode将安排由其他DataNode管理的块进行副本复制。</li> <li>DataNode所在机器通常配置有大量的硬盘空间。因为实际数据存储在DataNode中。</li> <li>DataNode会定期（dfs.heartbeat.interval配置项配置，默认是3秒）向NameNode发送心跳，如果NameNode长时间没有接受到DataNode发送的心跳， NameNode就会认为该DataNode失效。</li> <li>block汇报时间间隔取参数dfs.blockreport.intervalMsec,参数未配置的话默认为6小时.</li></ol> <br> <h3 id="_3．-hdfs的工作机制"><a href="#_3．-hdfs的工作机制" class="header-anchor">#</a> <strong>3． HDFS的工作机制</strong></h3> <p>NameNode负责管理整个文件系统元数据；DataNode负责管理具体文件数据块存储；Secondary NameNode协助NameNode进行元数据的备份。<br><code>HDFS的内部工作机制对客户端保持透明，客户端请求访问HDFS都是通过向NameNode申请来进行。</code></p> <div style="display:flex;"><img src="/assets/img/hdfs-1.31740735.jpg" alt="" align="left" style="display:block;"></div> <p><strong>3.1． HDFS写数据流程</strong></p> <p><strong>详细步骤解析</strong>：</p> <ol><li>client发起文件上传请求，通过RPC与NameNode建立通讯，NameNode检查目标文件是否已存在，父目录是否存在，返回是否可以上传；</li> <li>client请求第一个 block该传输到哪些DataNode服务器上；</li> <li>NameNode根据配置文件中指定的备份数量及机架感知原理进行文件分配，返回可用的DataNode的地址如：A，B，C；<br><em>注：Hadoop在设计时考虑到数据的安全与高效，数据文件默认在HDFS上存放三份，<strong>存储策略</strong>为本地一份，同机架内其它某一节点上一份，不同机架的某一节点上一份。</em></li> <li>client请求3台DataNode中的一台A上传数据（本质上是一个RPC调用，建立pipeline），A收到请求会继续调用B，然后B调用C，将整个pipeline建立完成，后逐级返回client；</li> <li>client开始往A上传第一个block（先从磁盘读取数据放到一个本地内存缓存），以packet为单位（默认64K），A收到一个packet就会传给B，B传给C；A每传一个packet会放入一个应答队列等待应答。</li> <li>数据被分割成一个个packet数据包在pipeline上依次传输，在pipeline反方向上，逐个发送ack（命令正确应答），最终由pipeline中第一个DataNode节点A将pipeline ack发送给client;</li> <li>当一个block传输完成之后，client再次请求NameNode上传第二个block到服务器。</li></ol> <p><strong>详细步骤图：(此图与上面步骤略有差别，但基本应该差不多)</strong></p> <div style="display:flex;"><img src="/assets/img/hdfs-2.75e47bcc.jpg" alt="" align="left" style="display:block;"></div> <p><strong>3.2． HDFS读数据流程</strong></p> <p><strong>详细步骤解析：</strong></p> <ol><li>Client向NameNode发起RPC请求，来确定请求文件block所在的位置；</li> <li>NameNode会视情况返回文件的部分或者全部block列表，对于每个block，NameNode都会返回含有该block副本的DataNode地址；</li> <li>这些返回的DN地址，会按照集群拓扑结构得出DataNode与客户端的距离，然后进行排序，排序两个规则：网络拓扑结构中距离Client近的排靠前；心跳机制中超时汇报的DN状态为STALE，这样的排靠后；</li> <li>Client选取排序靠前的DataNode来读取block，如果客户端本身就是DataNode,那么将从本地直接获取数据；</li> <li>底层上本质是建立Socket Stream（FSDataInputStream），重复的调用父类DataInputStream的read方法，直到这个块上的数据读取完毕；</li> <li>当读完列表的block后，若文件读取还没有结束，客户端会继续向NameNode获取下一批的block列表；</li> <li>读取完一个block都会进行checksum验证，如果读取DataNode时出现错误，客户端会通知NameNode，然后再从下一个拥有该block副本的DataNode继续读。</li> <li>read方法是并行的读取block信息，不是一块一块的读取；NameNode只是返回Client请求包含块的DataNode地址，并不是返回请求块的数据；</li> <li>最终读取来所有的block会合并成一个完整的最终文件。</li></ol> <p><strong>详细步骤图：</strong></p> <div style="display:flex;"><img src="/assets/img/hdfs-3.6f87d92d.jpg" alt="" align="left" style="display:block;"></div> <p>或者参考下图</p> <div style="display:flex;"><img src="/assets/img/hdfs-3-1.86cb91b4.jpg" alt="" align="left" style="display:block;"></div> <br> <h2 id="hdfs的应用开发"><a href="#hdfs的应用开发" class="header-anchor">#</a> <strong>HDFS的应用开发</strong></h2> <h3 id="hdfs的java-api操作"><a href="#hdfs的java-api操作" class="header-anchor">#</a> <strong>HDFS的JAVA API操作</strong></h3> <p>HDFS在生产应用中主要是客户端的开发，其核心步骤是从HDFS提供的api中构造一个HDFS的访问客户端对象，然后通过该客户端对象操作（增删改查）HDFS上的文件。</p> <p><strong>1．</strong> <strong>搭建开发环境</strong></p> <p>创建Maven工程，引入pom依赖</p> <div class="language-xml line-numbers-mode"><pre class="language-xml"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
         <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
         <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>hadoop-common<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
         <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.7.4<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
         <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
         <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>hadoop-hdfs<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
         <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.7.4<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
         <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
         <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>hadoop-client<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
         <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.7.4<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">&gt;</span></span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br></div></div><p><strong>配置windows平台Hadoop环境</strong></p> <p>在windows上做HDFS客户端应用开发，需要设置Hadoop环境,而且要求是windows平台编译的Hadoop,不然会报以下的错误:</p> <blockquote><p>Failed to locate the winutils binary in the hadoop binary path java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.</p></blockquote> <p>为此我们需要进行如下的操作：</p> <ul><li>在windows平台下编译Hadoop源码（可以参考资料编译，但不推荐）</li> <li>使用已经编译好的Windows版本Hadoop：hadoop-2.7.4-with-windows.tar.gz</li> <li>解压一份到windows的任意一个目录下</li> <li>在windows系统中配置HADOOP_HOME指向你解压的安装包目录</li> <li>在windows系统的path变量中加入HADOOP_HOME的bin目录</li></ul> <p><strong>2．</strong> <strong>构造客户端对象</strong></p> <p>在java中操作HDFS，主要涉及以下Class：</p> <p><code>Configuration：</code>该类的对象封转了客户端或者服务器的配置;<br><code>FileSystem：</code>该类的对象是一个文件系统对象，可以用该对象的一些方法来对文件进行操作，通过FileSystem的静态方法get获得该对象。<br><code>FileSystem fs = FileSystem.get(conf)</code></p> <p>get方法从conf中的一个参数 fs.defaultFS的配置值判断具体是什么类型的文件系统。如果我们的代码中没有指定fs.defaultFS，并且工程classpath下也没有给定相应的配置，conf中的默认值就来自于hadoop的jar包中的core-default.xml，默认值为： file:///，则获取的将不是一个DistributedFileSystem的实例，而是一个本地文件系统的客户端对象。</p> <p><strong>3．</strong> <strong>示例代码</strong></p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token class-name">Configuration</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">//这里指定使用的是hdfs文件系统</span>
conf<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">&quot;fs.defaultFS&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;hdfs://node-21:9000&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
             
<span class="token comment">//通过如下的方式进行客户端身份的设置</span>
<span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">&quot;HADOOP_USER_NAME&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;root&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 
<span class="token comment">//通过FileSystem的静态方法获取文件系统客户端对象</span>
<span class="token class-name">FileSystem</span> fs <span class="token operator">=</span> <span class="token class-name">FileSystem</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">//也可以通过如下的方式去指定文件系统的类型 并且同时设置用户身份</span>
<span class="token comment">//FileSystem fs = FileSystem.get(new URI(&quot;hdfs://node-21:9000&quot;), conf, &quot;root&quot;);</span>
 
<span class="token comment">//创建一个目录</span>
fs<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">&quot;/hdfsbyjava-ha&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 
<span class="token comment">//上传一个文件</span>
fs<span class="token punctuation">.</span><span class="token function">copyFromLocalFile</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">&quot;e:/hello.sh&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">&quot;/hdfsbyjava-ha&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 
<span class="token comment">//关闭我们的文件系统</span>
fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br></div></div><p>其他更多操作如文件增删改查请查看实例代码。</p> <p><strong>Stream流形式操作</strong></p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testUpload</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{</span> 
        <span class="token class-name">FSDataOutputStream</span> outputStream <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">&quot;/1.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span> 
        <span class="token class-name">FileInputStream</span> inputStream <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileInputStream</span><span class="token punctuation">(</span><span class="token string">&quot;D:\\1.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span> 
        <span class="token class-name">IOUtils</span><span class="token punctuation">.</span><span class="token function">copy</span><span class="token punctuation">(</span>inputStream<span class="token punctuation">,</span> outputStream<span class="token punctuation">)</span><span class="token punctuation">;</span> 
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/BigDataAndDistributedSystem/Hadoop/HadoopInstall.html" class="prev">Hadoop安装初体验</a></span> <span class="next"><a href="/BigDataAndDistributedSystem/Hadoop/MapReduce.html">MapReduce</a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.251ed5d9.js" defer></script><script src="/assets/js/2.858e58ff.js" defer></script><script src="/assets/js/38.61d0edc2.js" defer></script>
  </body>
</html>
