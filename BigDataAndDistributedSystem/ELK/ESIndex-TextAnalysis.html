<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>ES Index-Text Analysis | Yan&#39;s Blog Home</title>
    <meta name="description" content="Personal blog site">
    
    
    <link rel="preload" href="/assets/css/0.styles.659f981c.css" as="style"><link rel="preload" href="/assets/js/app.29af2d6c.js" as="script"><link rel="preload" href="/assets/js/2.858e58ff.js" as="script"><link rel="preload" href="/assets/js/62.64d7637a.js" as="script"><link rel="prefetch" href="/assets/js/10.5dcc1f52.js"><link rel="prefetch" href="/assets/js/100.0327e00b.js"><link rel="prefetch" href="/assets/js/101.404f187c.js"><link rel="prefetch" href="/assets/js/102.d78878ec.js"><link rel="prefetch" href="/assets/js/103.ec9aedef.js"><link rel="prefetch" href="/assets/js/104.39309514.js"><link rel="prefetch" href="/assets/js/105.afbf1884.js"><link rel="prefetch" href="/assets/js/106.8e9709d3.js"><link rel="prefetch" href="/assets/js/107.9712aa22.js"><link rel="prefetch" href="/assets/js/108.4158fdb6.js"><link rel="prefetch" href="/assets/js/109.ae61a303.js"><link rel="prefetch" href="/assets/js/11.34e3d90e.js"><link rel="prefetch" href="/assets/js/110.0abce6c9.js"><link rel="prefetch" href="/assets/js/111.b5c958e5.js"><link rel="prefetch" href="/assets/js/112.9b07d6a0.js"><link rel="prefetch" href="/assets/js/113.9d95243d.js"><link rel="prefetch" href="/assets/js/114.f759f9b9.js"><link rel="prefetch" href="/assets/js/115.fd833a74.js"><link rel="prefetch" href="/assets/js/116.1e5e62e4.js"><link rel="prefetch" href="/assets/js/117.952db9d4.js"><link rel="prefetch" href="/assets/js/118.ed9df468.js"><link rel="prefetch" href="/assets/js/119.f19ee9e0.js"><link rel="prefetch" href="/assets/js/12.cd237cda.js"><link rel="prefetch" href="/assets/js/120.24dbecef.js"><link rel="prefetch" href="/assets/js/121.41c70ddb.js"><link rel="prefetch" href="/assets/js/122.5205ca42.js"><link rel="prefetch" href="/assets/js/123.25aa20a6.js"><link rel="prefetch" href="/assets/js/124.11cc8c85.js"><link rel="prefetch" href="/assets/js/125.091331f4.js"><link rel="prefetch" href="/assets/js/126.471b335f.js"><link rel="prefetch" href="/assets/js/127.60ffdb36.js"><link rel="prefetch" href="/assets/js/128.9c5c36ef.js"><link rel="prefetch" href="/assets/js/129.36fd802b.js"><link rel="prefetch" href="/assets/js/13.de2ffe9f.js"><link rel="prefetch" href="/assets/js/130.822de8a4.js"><link rel="prefetch" href="/assets/js/131.697750e2.js"><link rel="prefetch" href="/assets/js/132.fd5faa78.js"><link rel="prefetch" href="/assets/js/133.cf327ef4.js"><link rel="prefetch" href="/assets/js/134.6cdb8690.js"><link rel="prefetch" href="/assets/js/135.906c8800.js"><link rel="prefetch" href="/assets/js/136.43585d13.js"><link rel="prefetch" href="/assets/js/137.3c7ddb41.js"><link rel="prefetch" href="/assets/js/138.e3274ead.js"><link rel="prefetch" href="/assets/js/139.7fa38b58.js"><link rel="prefetch" href="/assets/js/14.9d6406e7.js"><link rel="prefetch" href="/assets/js/140.1b026dad.js"><link rel="prefetch" href="/assets/js/141.c1adfec5.js"><link rel="prefetch" href="/assets/js/142.2810013c.js"><link rel="prefetch" href="/assets/js/143.af96e2f9.js"><link rel="prefetch" href="/assets/js/144.923a7d38.js"><link rel="prefetch" href="/assets/js/145.d88163de.js"><link rel="prefetch" href="/assets/js/146.2134dd3e.js"><link rel="prefetch" href="/assets/js/147.9925c468.js"><link rel="prefetch" href="/assets/js/148.109297cc.js"><link rel="prefetch" href="/assets/js/149.ae529d47.js"><link rel="prefetch" href="/assets/js/15.fe3428fa.js"><link rel="prefetch" href="/assets/js/150.705297ac.js"><link rel="prefetch" href="/assets/js/151.a715116f.js"><link rel="prefetch" href="/assets/js/152.57feb7ad.js"><link rel="prefetch" href="/assets/js/153.fd5cde7c.js"><link rel="prefetch" href="/assets/js/154.8cedd5d3.js"><link rel="prefetch" href="/assets/js/155.042308eb.js"><link rel="prefetch" href="/assets/js/156.54044f43.js"><link rel="prefetch" href="/assets/js/157.69e07481.js"><link rel="prefetch" href="/assets/js/158.5b91c0e7.js"><link rel="prefetch" href="/assets/js/159.ccb310d2.js"><link rel="prefetch" href="/assets/js/16.7976352c.js"><link rel="prefetch" href="/assets/js/160.08c90bea.js"><link rel="prefetch" href="/assets/js/161.943b1e4b.js"><link rel="prefetch" href="/assets/js/162.8092cc22.js"><link rel="prefetch" href="/assets/js/163.3c82e51b.js"><link rel="prefetch" href="/assets/js/164.0fd751fe.js"><link rel="prefetch" href="/assets/js/165.60d778eb.js"><link rel="prefetch" href="/assets/js/166.54d7340a.js"><link rel="prefetch" href="/assets/js/167.5fd6aaa3.js"><link rel="prefetch" href="/assets/js/168.205929f8.js"><link rel="prefetch" href="/assets/js/169.873b90b1.js"><link rel="prefetch" href="/assets/js/17.4a461074.js"><link rel="prefetch" href="/assets/js/170.68c49359.js"><link rel="prefetch" href="/assets/js/171.d8f93304.js"><link rel="prefetch" href="/assets/js/172.6b496cc7.js"><link rel="prefetch" href="/assets/js/173.f276a0ce.js"><link rel="prefetch" href="/assets/js/174.09cb41e2.js"><link rel="prefetch" href="/assets/js/175.c77ce8d9.js"><link rel="prefetch" href="/assets/js/176.01ab9f3f.js"><link rel="prefetch" href="/assets/js/177.e9733435.js"><link rel="prefetch" href="/assets/js/178.02e78943.js"><link rel="prefetch" href="/assets/js/179.0d14e948.js"><link rel="prefetch" href="/assets/js/18.8264b169.js"><link rel="prefetch" href="/assets/js/180.9a15f295.js"><link rel="prefetch" href="/assets/js/181.d5bcbada.js"><link rel="prefetch" href="/assets/js/182.571b87a8.js"><link rel="prefetch" href="/assets/js/183.0ce45547.js"><link rel="prefetch" href="/assets/js/184.8397e2fe.js"><link rel="prefetch" href="/assets/js/185.3a38f733.js"><link rel="prefetch" href="/assets/js/186.881a0fab.js"><link rel="prefetch" href="/assets/js/187.17663dea.js"><link rel="prefetch" href="/assets/js/188.471fcd9b.js"><link rel="prefetch" href="/assets/js/189.69430297.js"><link rel="prefetch" href="/assets/js/19.e6227b20.js"><link rel="prefetch" href="/assets/js/190.357b4cc8.js"><link rel="prefetch" href="/assets/js/191.f2d049a7.js"><link rel="prefetch" href="/assets/js/192.e2d30cca.js"><link rel="prefetch" href="/assets/js/193.2fbcbc68.js"><link rel="prefetch" href="/assets/js/194.61d0acd9.js"><link rel="prefetch" href="/assets/js/195.33b772c3.js"><link rel="prefetch" href="/assets/js/196.7d35848a.js"><link rel="prefetch" href="/assets/js/197.4b958d27.js"><link rel="prefetch" href="/assets/js/198.dfbfba98.js"><link rel="prefetch" href="/assets/js/199.f6c7aacb.js"><link rel="prefetch" href="/assets/js/20.65ad9b00.js"><link rel="prefetch" href="/assets/js/200.6a05302e.js"><link rel="prefetch" href="/assets/js/201.be446c97.js"><link rel="prefetch" href="/assets/js/202.d058ca1d.js"><link rel="prefetch" href="/assets/js/203.ef2b609c.js"><link rel="prefetch" href="/assets/js/204.dab38ee5.js"><link rel="prefetch" href="/assets/js/21.bf0f72d4.js"><link rel="prefetch" href="/assets/js/22.0ed457bc.js"><link rel="prefetch" href="/assets/js/23.789f7b2b.js"><link rel="prefetch" href="/assets/js/24.f151ffcb.js"><link rel="prefetch" href="/assets/js/25.1edb28e8.js"><link rel="prefetch" href="/assets/js/26.6a5f804d.js"><link rel="prefetch" href="/assets/js/27.98408441.js"><link rel="prefetch" href="/assets/js/28.fe24662a.js"><link rel="prefetch" href="/assets/js/29.fbd2340a.js"><link rel="prefetch" href="/assets/js/3.753236a7.js"><link rel="prefetch" href="/assets/js/30.30b44255.js"><link rel="prefetch" href="/assets/js/31.510d262b.js"><link rel="prefetch" href="/assets/js/32.c204bc79.js"><link rel="prefetch" href="/assets/js/33.5fa66039.js"><link rel="prefetch" href="/assets/js/34.6db47b26.js"><link rel="prefetch" href="/assets/js/35.fcb88dd5.js"><link rel="prefetch" href="/assets/js/36.e294e99d.js"><link rel="prefetch" href="/assets/js/37.0a98cae2.js"><link rel="prefetch" href="/assets/js/38.94af8189.js"><link rel="prefetch" href="/assets/js/39.e7017f9b.js"><link rel="prefetch" href="/assets/js/4.efbefbf5.js"><link rel="prefetch" href="/assets/js/40.b7a1deeb.js"><link rel="prefetch" href="/assets/js/41.ae4d7d1e.js"><link rel="prefetch" href="/assets/js/42.5dc5c7f6.js"><link rel="prefetch" href="/assets/js/43.1abeab08.js"><link rel="prefetch" href="/assets/js/44.2b0e19f3.js"><link rel="prefetch" href="/assets/js/45.903efdc0.js"><link rel="prefetch" href="/assets/js/46.0684656f.js"><link rel="prefetch" href="/assets/js/47.6425b35e.js"><link rel="prefetch" href="/assets/js/48.551e2caa.js"><link rel="prefetch" href="/assets/js/49.34841bc0.js"><link rel="prefetch" href="/assets/js/5.d3774f5f.js"><link rel="prefetch" href="/assets/js/50.48ce1d7e.js"><link rel="prefetch" href="/assets/js/51.1820aa29.js"><link rel="prefetch" href="/assets/js/52.5317c537.js"><link rel="prefetch" href="/assets/js/53.65c5ef62.js"><link rel="prefetch" href="/assets/js/54.31ed2a5e.js"><link rel="prefetch" href="/assets/js/55.4f9933ab.js"><link rel="prefetch" href="/assets/js/56.beb74e07.js"><link rel="prefetch" href="/assets/js/57.705bc19e.js"><link rel="prefetch" href="/assets/js/58.f5fd656b.js"><link rel="prefetch" href="/assets/js/59.4f21d836.js"><link rel="prefetch" href="/assets/js/6.f082ca37.js"><link rel="prefetch" href="/assets/js/60.fc3cf484.js"><link rel="prefetch" href="/assets/js/61.b5032b43.js"><link rel="prefetch" href="/assets/js/63.2a71075b.js"><link rel="prefetch" href="/assets/js/64.21eb4820.js"><link rel="prefetch" href="/assets/js/65.11535a8c.js"><link rel="prefetch" href="/assets/js/66.cc057448.js"><link rel="prefetch" href="/assets/js/67.5782c958.js"><link rel="prefetch" href="/assets/js/68.35886dae.js"><link rel="prefetch" href="/assets/js/69.934aa057.js"><link rel="prefetch" href="/assets/js/7.9a79fd87.js"><link rel="prefetch" href="/assets/js/70.53c7c7a2.js"><link rel="prefetch" href="/assets/js/71.0e82b1c6.js"><link rel="prefetch" href="/assets/js/72.0f5ba0b4.js"><link rel="prefetch" href="/assets/js/73.3dabc9cd.js"><link rel="prefetch" href="/assets/js/74.b2ae43f6.js"><link rel="prefetch" href="/assets/js/75.482aa6b4.js"><link rel="prefetch" href="/assets/js/76.2f88e50b.js"><link rel="prefetch" href="/assets/js/77.d916e87e.js"><link rel="prefetch" href="/assets/js/78.35465388.js"><link rel="prefetch" href="/assets/js/79.03bce65e.js"><link rel="prefetch" href="/assets/js/8.60d5a8a9.js"><link rel="prefetch" href="/assets/js/80.96678f59.js"><link rel="prefetch" href="/assets/js/81.631a8496.js"><link rel="prefetch" href="/assets/js/82.41c1aeb7.js"><link rel="prefetch" href="/assets/js/83.16d5e455.js"><link rel="prefetch" href="/assets/js/84.195ca01f.js"><link rel="prefetch" href="/assets/js/85.d850d4dd.js"><link rel="prefetch" href="/assets/js/86.32d87d56.js"><link rel="prefetch" href="/assets/js/87.5f97a4f6.js"><link rel="prefetch" href="/assets/js/88.f5b0bbdb.js"><link rel="prefetch" href="/assets/js/89.9f9150f5.js"><link rel="prefetch" href="/assets/js/9.b09584f6.js"><link rel="prefetch" href="/assets/js/90.81e868a0.js"><link rel="prefetch" href="/assets/js/91.a4a66d6f.js"><link rel="prefetch" href="/assets/js/92.e992da4f.js"><link rel="prefetch" href="/assets/js/93.8f0f273c.js"><link rel="prefetch" href="/assets/js/94.7c76483d.js"><link rel="prefetch" href="/assets/js/95.448f049a.js"><link rel="prefetch" href="/assets/js/96.29982e03.js"><link rel="prefetch" href="/assets/js/97.4fdd8a0b.js"><link rel="prefetch" href="/assets/js/98.74cfc635.js"><link rel="prefetch" href="/assets/js/99.abdd1b46.js">
    <link rel="stylesheet" href="/assets/css/0.styles.659f981c.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">Yan's Blog Home</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">Blog Home</a></div><div class="nav-item"><a href="/index/" class="nav-link">Technical Blog Home</a></div><div class="nav-item"><a href="https://heyan.site:8003/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Other Blog Home
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div><div class="nav-item"><a href="/comments.html" class="nav-link">留言</a></div><div class="nav-item"><a href="http://heyan.site/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Site Home
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">Blog Home</a></div><div class="nav-item"><a href="/index/" class="nav-link">Technical Blog Home</a></div><div class="nav-item"><a href="https://heyan.site:8003/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Other Blog Home
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div><div class="nav-item"><a href="/comments.html" class="nav-link">留言</a></div><div class="nav-item"><a href="http://heyan.site/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Site Home
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>大数据和分布式系统</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>分布式系统理论</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>分布式协调服务</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>数据摄取 Layer</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>数据流 Layer</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>数据存储 Layer</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>数据处理 Layer</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>数据分析 Layer (OLAP)</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>分布式系统基础框架Hadoop</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Data Platform - Splunk</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>Data Platform - ELK</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/BigDataAndDistributedSystem/ELK/" class="sidebar-link">Data Platform - ELK</a></li><li><a href="/BigDataAndDistributedSystem/ELK/ESConcepts-base.html" class="sidebar-link">ES 概念与总结</a></li><li><a href="/BigDataAndDistributedSystem/ELK/ESConcepts-cluster.html" class="sidebar-link">ES 原理-分布式特性</a></li><li><a href="/BigDataAndDistributedSystem/ELK/ESConcepts-index.html" class="sidebar-link">ES 原理-倒排索引</a></li><li><a href="/BigDataAndDistributedSystem/ELK/ESConcepts-AnalysisAndRelated.html" class="sidebar-link">ES 原理-分词器 &amp; 搜索相关性</a></li><li><a href="/BigDataAndDistributedSystem/ELK/ESIndex-basicoperation.html" class="sidebar-link">ES Index-基本操作与并发</a></li><li><a href="/BigDataAndDistributedSystem/ELK/ESIndex-mapping.html" class="sidebar-link">ES Index-Mapping &amp; Setting</a></li><li><a href="/BigDataAndDistributedSystem/ELK/ESIndex-IndexTemplate.html" class="sidebar-link">ES Index-Index Template</a></li><li><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html" class="active sidebar-link">ES Index-Text Analysis</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_1-text-analysis-概述" class="sidebar-link">1. Text Analysis 概述</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_1-1-tokenization" class="sidebar-link">1.1 Tokenization</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_1-2-normalization" class="sidebar-link">1.2 Normalization</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_1-3-自定义文本分析" class="sidebar-link">1.3 自定义文本分析</a></li></ul></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_2-text-analysis-基本概念" class="sidebar-link">2. Text Analysis 基本概念</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_2-1-analyzer-组成" class="sidebar-link">2.1 Analyzer 组成</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_2-2-stemming-词干分析" class="sidebar-link">2.2 Stemming 词干分析</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_2-3-token-graphs-分词图" class="sidebar-link">2.3 Token graphs 分词图</a></li></ul></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_3-配置-text-analysis" class="sidebar-link">3. 配置 Text Analysis</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_3-1-使用-analyzer-api-测试" class="sidebar-link">3.1 使用 Analyzer API 测试</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_3-2-配置内置的-analyzer" class="sidebar-link">3.2 配置内置的 Analyzer</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_3-3-配置自定义的-analyzer" class="sidebar-link">3.3 配置自定义的 Analyzer</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_3-4-指定-analyzer" class="sidebar-link">3.4 指定 Analyzer</a></li></ul></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#内置-analyzer-详解" class="sidebar-link">内置 Analyzer 详解</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_1-fingerprint-analyzer" class="sidebar-link">1. Fingerprint analyzer</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_2-keyword-analyzer" class="sidebar-link">2. Keyword analyzer</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_3-language-analyzer" class="sidebar-link">3. Language analyzer</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_4-pattern-analyzer" class="sidebar-link">4. Pattern analyzer</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_5-simple-analyzer" class="sidebar-link">5. Simple analyzer</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_6-standard-analyzer" class="sidebar-link">6. Standard analyzer</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_7-stop-analyzer" class="sidebar-link">7. Stop analyzer</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_8-whitespace-analyzer" class="sidebar-link">8. Whitespace analyzer</a></li></ul></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#内置-character-filter-详解" class="sidebar-link">内置 Character filter 详解</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_1-html-strip-character-filter" class="sidebar-link">1. HTML strip character filter</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_2-mapping-character-filter" class="sidebar-link">2. Mapping character filter</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_3-pattern-replace-character-filter" class="sidebar-link">3. Pattern replace character filter</a></li></ul></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#内置-tokenizer-详解" class="sidebar-link">内置 Tokenizer 详解</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_1-character-group-tokenizer" class="sidebar-link">1. Character group tokenizer</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_2-classic-tokenizer" class="sidebar-link">2. Classic tokenizer</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_3-edge-n-gram-tokenizer" class="sidebar-link">3. Edge n-gram tokenizer</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_4-keyword-tokenizer" class="sidebar-link">4. Keyword tokenizer</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_5-letter-tokenizer" class="sidebar-link">5. Letter tokenizer</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_6-lowercase-tokenizer" class="sidebar-link">6. Lowercase tokenizer</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_7-n-gram-tokenzier" class="sidebar-link">7. N-gram tokenzier</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_8-path-hierarchy-tokenizer" class="sidebar-link">8. Path hierarchy tokenizer</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_9-pattern-tokenizer" class="sidebar-link">9. Pattern tokenizer</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_10-simple-pattern-tokenizer" class="sidebar-link">10. Simple pattern tokenizer</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_11-simple-pattern-split-tokenizer" class="sidebar-link">11. Simple pattern split tokenizer</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_12-standard-tokenizer" class="sidebar-link">12. Standard tokenizer</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_13-thai-tokenizer" class="sidebar-link">13. Thai tokenizer</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_14-uax-url-email-tokenzier" class="sidebar-link">14. UAX URL email tokenzier</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_15-whitespace-tokenizer" class="sidebar-link">15. Whitespace tokenizer</a></li></ul></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#内置-token-filter-详解" class="sidebar-link">内置 Token filter 详解</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_1-apostrophe-token-filter" class="sidebar-link">1. Apostrophe token filter</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_2-ascii-folding-token-filter" class="sidebar-link">2. ASCII folding token filter</a></li><li class="sidebar-sub-header"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-TextAnalysis.html#_3-cjk-bigram-token-filter" class="sidebar-link">3. CJK bigram token filter</a></li></ul></li></ul></li><li><a href="/BigDataAndDistributedSystem/ELK/ESIndex-IngestAndScript.html" class="sidebar-link">ES Index-Ingest|Script</a></li><li><a href="/BigDataAndDistributedSystem/ELK/ESUsage-crud.html" class="sidebar-link">ES 使用-基本CRUD</a></li><li><a href="/BigDataAndDistributedSystem/ELK/ESSearch-search.html" class="sidebar-link">ES 搜索-搜索相关</a></li><li><a href="/BigDataAndDistributedSystem/ELK/ESSearch-queryDSL.html" class="sidebar-link">ES 搜索-查询DSL</a></li><li><a href="/BigDataAndDistributedSystem/ELK/ESSearch-aggregation.html" class="sidebar-link">ES 搜索-聚合</a></li></ul></section></li><li><a href="/index/" class="sidebar-link">&lt; 首页</a></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default" data-v-73cb4eb0 data-v-73cb4eb0><h1 id="es-index-text-analysis" data-v-73cb4eb0><a href="#es-index-text-analysis" class="header-anchor" data-v-73cb4eb0>#</a> ES Index-Text Analysis</h1> <div class="custom-block tip" data-v-73cb4eb0><p class="custom-block-title" data-v-73cb4eb0>转载</p> <ul data-v-73cb4eb0><li data-v-73cb4eb0><a href="https://www.yuque.com/xiongsanxiansheng/qfvqxo/mpst8x" target="_self" rel="noopener noreferrer" data-v-73cb4eb0>https://www.yuque.com/xiongsanxiansheng/qfvqxo/mpst8x</a></li> <li data-v-73cb4eb0><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.9.html" target="_self" rel="noopener noreferrer" data-v-73cb4eb0>https://www.elastic.co/guide/en/elasticsearch/reference/7.9</a></li></ul></div> <p data-v-73cb4eb0>文本分析是将非结构化文本 (如电子邮件的正文或产品描述) 转换为结构化格式，以便于搜索的过程。如果索引中包含文本字段，或者文本搜索没有返回预期的结果，就可以通过配置文本 Analysis 来微调搜索。</p> <h2 id="_1-text-analysis-概述" data-v-73cb4eb0><a href="#_1-text-analysis-概述" class="header-anchor" data-v-73cb4eb0>#</a> 1. Text Analysis 概述</h2> <p data-v-73cb4eb0>文本分析让 Elasticsearch 能够执行全文搜索，返回所有相关结果，而不仅仅是精确匹配。</p> <ul data-v-73cb4eb0><li data-v-73cb4eb0>精确匹配
<ul data-v-73cb4eb0><li data-v-73cb4eb0>2017-01-01，exact value，搜索的时候，必须输入 2017-01-01，才能搜索出来。如果你输入一个 01，是搜索不出来的；</li></ul></li> <li data-v-73cb4eb0>全文搜索
<ul data-v-73cb4eb0><li data-v-73cb4eb0>就不是说单纯的只是匹配完整的一个值，而是可以对值进行拆分词语后（分词）进行匹配，也可以通过缩写、时态、大小写、同义词等进行匹配；</li> <li data-v-73cb4eb0>你在文本里搜索 Quick fox jumps，可能不仅希望返回包含 quick foxs 的文档，也希望返回 fox leap 的文档，因为 jump 和 leap 是同义词，相同意思的也满足需求可以作为结果返回；</li></ul></li></ul> <h3 id="_1-1-tokenization" data-v-73cb4eb0><a href="#_1-1-tokenization" class="header-anchor" data-v-73cb4eb0>#</a> 1.1 Tokenization</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0>文本分析通过 tokenization 分词操作，让全文搜索变成了可能。</li> <li data-v-73cb4eb0>Tokenization 分词操作，将文本分解成更小的块，称为 token，大多情况下，这些 token 是单独的单词。</li> <li data-v-73cb4eb0>将一段句子拆分成一个一个的单个的单词，并分别将每个单词编入索引，只要匹配到一个搜索关键词就可以匹配到结果。</li></ul> <h3 id="_1-2-normalization" data-v-73cb4eb0><a href="#_1-2-normalization" class="header-anchor" data-v-73cb4eb0>#</a> 1.2 Normalization</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0>切分词语后，文本分析就可以对单个 token 进行匹配，但是每个 token 的匹配也只是进行字面意义上的直接比较；</li> <li data-v-73cb4eb0>我们希望可以在匹配关键词时，可以忽略大小写，时态，同时只要与搜索词相近意思的也符合条件，将结果返回；</li> <li data-v-73cb4eb0>为了解决这个问题，文本分析将切分词语后的 token 转化为一个标准化的格式，这允许匹配到与搜索词不完全相同但足够相似的相关 token，例如：
<ul data-v-73cb4eb0><li data-v-73cb4eb0>Quick 小写化：quick；</li> <li data-v-73cb4eb0>foxes 简化它的词根：fox；</li> <li data-v-73cb4eb0>jump、leap 这样的同义词，可以作为一个单词进行索引：jump；</li></ul></li> <li data-v-73cb4eb0>为了确保搜索词与这些 token 匹配，可以对搜索短语使用相同的分词和规范化规则，例如，搜索短语 Foxes leap 会被规范化为搜索关键词 fox jump；</li></ul> <h3 id="_1-3-自定义文本分析" data-v-73cb4eb0><a href="#_1-3-自定义文本分析" class="header-anchor" data-v-73cb4eb0>#</a> 1.3 自定义文本分析</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0>文本分析是由分词器执行的，分词器包含一组规则来控制文本分析的过程；</li> <li data-v-73cb4eb0>ES 默认分词器是 <font color="red" data-v-73cb4eb0> standard analyzer </font>；</li> <li data-v-73cb4eb0>如果想自定义文本分析，可以使用其他的内置分词器，或者使用一个自定义的分词器；</li> <li data-v-73cb4eb0>一个自定义的分词器可以控制文本分析的每一步，包括：
<ul data-v-73cb4eb0><li data-v-73cb4eb0>在 tokenization 之前对文本进行修改；</li> <li data-v-73cb4eb0>控制文本的切词规则；</li> <li data-v-73cb4eb0>在索引 token 前，对 token 进行规范化；</li></ul></li></ul> <h2 id="_2-text-analysis-基本概念" data-v-73cb4eb0><a href="#_2-text-analysis-基本概念" class="header-anchor" data-v-73cb4eb0>#</a> 2. Text Analysis 基本概念</h2> <h3 id="_2-1-analyzer-组成" data-v-73cb4eb0><a href="#_2-1-analyzer-组成" class="header-anchor" data-v-73cb4eb0>#</a> 2.1 Analyzer 组成</h3> <p data-v-73cb4eb0>无论是内置的，还是自定义的 Analyzer 都是由底层的三个模块组成：character filters, tokenizers, and token filters；</p> <p data-v-73cb4eb0>我们可以自己组合这些模块来定义新的自定义 Analyzer；</p> <h4 id="_1）character-filters" data-v-73cb4eb0><a href="#_1）character-filters" class="header-anchor" data-v-73cb4eb0>#</a> 1）Character filters</h4> <ul data-v-73cb4eb0><li data-v-73cb4eb0>针对原始文本进行处理，例如去除 HTML 标记；</li> <li data-v-73cb4eb0>一个 Analyzer 可以由 0 个或多个 character filter，按顺序使用；</li> <li data-v-73cb4eb0><a href="/BigData/ELK/ES-TextAnalysis.html#内置-character-filter-详解" data-v-73cb4eb0><strong data-v-73cb4eb0>《内置的 Character filter 详解》</strong></a></li></ul> <h4 id="_2）tokenizer" data-v-73cb4eb0><a href="#_2）tokenizer" class="header-anchor" data-v-73cb4eb0>#</a> 2）Tokenizer</h4> <ul data-v-73cb4eb0><li data-v-73cb4eb0>分词器，将接收的文本按照一定的规则进行切分；</li> <li data-v-73cb4eb0>Tokenizer 还负责记录每个 token 在文本中的顺序和位置，以及 token 所代表的原始单词的开始字符与结束字符的偏移量；</li> <li data-v-73cb4eb0>一个 Analyzer 文本分析器只能有一个 Tokenizer 分词器；</li> <li data-v-73cb4eb0><a href="/BigData/ELK/ES-TextAnalysis.html#内置-tokenizer-详解" data-v-73cb4eb0><strong data-v-73cb4eb0>《内置的 Tokenizer 详解》</strong></a></li></ul> <h4 id="_3）token-filters" data-v-73cb4eb0><a href="#_3）token-filters" class="header-anchor" data-v-73cb4eb0>#</a> 3）Token filters</h4> <ul data-v-73cb4eb0><li data-v-73cb4eb0>针对切分的单词进行加工，比如转为小写、删除 stopwords、增加同义词;</li> <li data-v-73cb4eb0>规范化操作 Normalization；</li> <li data-v-73cb4eb0>Token filters 不允许改变每个 token 记录在 Tokenizer 中的位置或字符偏移量；</li> <li data-v-73cb4eb0>一个 Analyzer 可以有 0 个或多个 Token filters，它们按顺序使用；</li> <li data-v-73cb4eb0><a href="/BigData/ELK/ES-TextAnalysis.html#内置-token-filter-详解" data-v-73cb4eb0><strong data-v-73cb4eb0>《内置的 Token filter 详解》</strong></a></li></ul> <h3 id="_2-2-stemming-词干分析" data-v-73cb4eb0><a href="#_2-2-stemming-词干分析" class="header-anchor" data-v-73cb4eb0>#</a> 2.2 Stemming 词干分析</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0>Stemming，就是将一个单词还原成它的词根形式的过程，这是 <strong data-v-73cb4eb0>Normalization</strong> 规范化中的一种方式。
<ul data-v-73cb4eb0><li data-v-73cb4eb0>例如：walking 和 walked 有相同的词根 walk，一旦进行了词根分析，任何一个词的出现都将在搜索中与另一个词匹配；</li></ul></li> <li data-v-73cb4eb0>Stemming 词干分析虽然依赖于语言，但是通常需要移除单词的前缀和后缀；</li> <li data-v-73cb4eb0>某些情况下，一些词的被词干分析后得到的词根不是一个正确的单词，但它在搜索中并不重要，如果一个单词的所有变体都简化为相同的词根形式，那么它们也将正确匹配；
<ul data-v-73cb4eb0><li data-v-73cb4eb0>例如：jumping 和 jumpiness 经过词干分析后都是 jumpi，但 jumpi 不是一个正确的单词，但是不影响搜索；</li></ul></li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>Stemmer token filters</strong>，token 词干过滤器，es 中的词干分析过程是由它来处理的，有以下几类：
<ul data-v-73cb4eb0><li data-v-73cb4eb0>Algorithmic stemmers 算法词干分析器，根据一组规则进行词干分析；</li> <li data-v-73cb4eb0>Dictionary stemmers 字典词干分析器，通过查字典来对单词进行词干还原；</li></ul></li></ul> <h4 id="_1）algorithmic-stemmers" data-v-73cb4eb0><a href="#_1）algorithmic-stemmers" class="header-anchor" data-v-73cb4eb0>#</a> 1）Algorithmic stemmers</h4> <ul data-v-73cb4eb0><li data-v-73cb4eb0><p data-v-73cb4eb0>算法词干分析器对每个单词应用一系列规则，将其简化为根形式。</p> <ul data-v-73cb4eb0><li data-v-73cb4eb0>例如，用于英语的 Algorithmic stemmers 可能会从复数单词的末尾去掉 -s 和 -es 后缀；</li></ul></li> <li data-v-73cb4eb0><p data-v-73cb4eb0>优势：</p> <ul data-v-73cb4eb0><li data-v-73cb4eb0>很少的配置，而且可以在大多数情况下满足需求；</li> <li data-v-73cb4eb0>占用的内存很少；</li> <li data-v-73cb4eb0>通常比 Dictionary stemmers 要快；</li></ul></li> <li data-v-73cb4eb0><p data-v-73cb4eb0>缺点：</p> <ul data-v-73cb4eb0><li data-v-73cb4eb0>大多数的 Algorithmic stemmers 只能对包含词根的单词进行简化，如果是不包含词根的不规则单词，那么就不能进行转化，例如：
<ul data-v-73cb4eb0><li data-v-73cb4eb0>be, are, and am；</li> <li data-v-73cb4eb0>mouse and mice；</li> <li data-v-73cb4eb0>foot and feet；</li></ul></li></ul></li> <li data-v-73cb4eb0><p data-v-73cb4eb0>以下 token filters 使用了 Algorithmic stemmers：</p> <ul data-v-73cb4eb0><li data-v-73cb4eb0>stemmer，它为几种语言提供算法词干分析；</li> <li data-v-73cb4eb0>kstem，一种用于英语的词干分析器，它将算法词干分析与内置字典结合在一起；</li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>porter_stem</strong>，<strong data-v-73cb4eb0>官方推荐</strong>的<strong data-v-73cb4eb0>英语</strong>词干分析器；</li> <li data-v-73cb4eb0>snowball，它为几种语言使用基于滚雪球的词干分析规则；</li></ul></li></ul> <h4 id="_2）dictionary-stemmers" data-v-73cb4eb0><a href="#_2）dictionary-stemmers" class="header-anchor" data-v-73cb4eb0>#</a> 2）Dictionary stemmers</h4> <ul data-v-73cb4eb0><li data-v-73cb4eb0><p data-v-73cb4eb0>字典词干分析器在提供的字典中查找单词，用字典中的词根单词替换未词根化的单词变体；</p></li> <li data-v-73cb4eb0><p data-v-73cb4eb0>理论上，Dictionary stemmers 很适合以下情况;</p> <ul data-v-73cb4eb0><li data-v-73cb4eb0>对不规则的单词进行词干分析；</li> <li data-v-73cb4eb0>区分拼写很像，但是概念上不相关的词，例如:
<ul data-v-73cb4eb0><li data-v-73cb4eb0>organ、organization；</li> <li data-v-73cb4eb0>broker、broken；</li></ul></li></ul></li> <li data-v-73cb4eb0><p data-v-73cb4eb0>实际上，<strong data-v-73cb4eb0>Algorithmic stemmers 的表现通常优于 Dictionary stemmers</strong>。这是因为 Dictionary stemmers 有以下的缺点：</p> <ul data-v-73cb4eb0><li data-v-73cb4eb0>字典的质量
<ul data-v-73cb4eb0><li data-v-73cb4eb0>Dictionary stemmers 好坏取决于它的字典。为了发挥作用，这些词典必须包含大量的单词，定期更新，并随语言趋势而变化。通常情况下，当一本词典问世时，它已经是不完整的，它的一些条目已经过时了。</li></ul></li> <li data-v-73cb4eb0>大小和性能
<ul data-v-73cb4eb0><li data-v-73cb4eb0>Dictionary stemmers 必须将字典中的所有单词、前缀和后缀加载到内存中。这可能会使用大量的RAM。低质量的字典可能在移除前缀和后缀的时候效率也很低，这可能会大大降低词干分析的速度。</li></ul></li></ul></li> <li data-v-73cb4eb0><p data-v-73cb4eb0>hunspell，就是使用的字典词干分析器；</p> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>官方建议</strong>：在使用 hunspell 前，先试试 Algorithmic stemmers；</li></ul></li></ul> <blockquote data-v-73cb4eb0><p data-v-73cb4eb0>有时，词干分析会产生拼写类似但在概念上不相关的共享根词。例如，stemmer 会将 skies 和 skiing 简化为同一个词根：ski。</p> <p data-v-73cb4eb0>为了防止这种情况并更好地控制词根分析，可以使用以下的 token filters：</p> <ul data-v-73cb4eb0><li data-v-73cb4eb0>stemmer_override，它允许您定义针对特定 token 进行词干分析的规则；</li> <li data-v-73cb4eb0>keyword_marker，它将特定的 tokens 定义为 keyword，keyword 类型的 tokens 将不会被后续的 stemmer token filters 处理；</li> <li data-v-73cb4eb0>conditional，与 keyword_marker 类似，将 tokens 定义为 keyword 类型；</li></ul> <p data-v-73cb4eb0>对于内置的词干分析器，可以使用 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-lang-analyzer.html#_excluding_words_from_stemming" target="_self" rel="noopener noreferrer" data-v-73cb4eb0>stem_exclusion</a> 参数来指定一个不会被词根化的单词列表；</p></blockquote> <h3 id="_2-3-token-graphs-分词图" data-v-73cb4eb0><a href="#_2-3-token-graphs-分词图" class="header-anchor" data-v-73cb4eb0>#</a> 2.3 Token graphs 分词图</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0>当 tokenizer 分词器将文本切分成 token 流时，它还会记录以下信息：
<ul data-v-73cb4eb0><li data-v-73cb4eb0>position：每个 token 在 token 流中的位置；</li> <li data-v-73cb4eb0>positionLength，token 在 token 流占的位置个数；</li></ul></li> <li data-v-73cb4eb0>使用 position 和 positionLength，就可以为一个 token 流生成一个 token graph，每一个 position 代表一个节点，每个 token 代表一个指向下一个 position 的边；</li></ul> <div style="display:flex;" data-v-73cb4eb0><img src="https://www.elastic.co/guide/en/elasticsearch/reference/7.9/images/analysis/token-graph-qbf-ex.svg" alt="" align="left" style="zoom:100%;display:block;" data-v-73cb4eb0></div> <h4 id="_1）synonyms-同义词" data-v-73cb4eb0><a href="#_1）synonyms-同义词" class="header-anchor" data-v-73cb4eb0>#</a> 1）Synonyms 同义词</h4> <ul data-v-73cb4eb0><li data-v-73cb4eb0>一些 token filter 会向 token stream 中添加一些新的 token（例如，同义词）。这些新增的 token 的 position 通常与它们的同义词分布在相同的位置。</li></ul> <div style="display:flex;" data-v-73cb4eb0><img src="https://www.elastic.co/guide/en/elasticsearch/reference/7.9/images/analysis/token-graph-qbf-synonym-ex.svg" alt="" align="left" style="zoom:100%;display:block;" data-v-73cb4eb0></div> <h4 id="_2）multi-position-tokens-横跨多个position的token" data-v-73cb4eb0><a href="#_2）multi-position-tokens-横跨多个position的token" class="header-anchor" data-v-73cb4eb0>#</a> 2）Multi-position tokens 横跨多个position的token</h4> <ul data-v-73cb4eb0><li data-v-73cb4eb0>一些 token filter 会向 token stream 中添加一些横跨多个 position 的 token。这类 token 通常时一些单词组成的词组的缩写，例如：atm 是 automatic teller machine 的同义词。</li> <li data-v-73cb4eb0>但是，只有某些 token filter 才能被称为 graph token filter，会准确的记录这类 multi_position token 的 positionLength：
<ul data-v-73cb4eb0><li data-v-73cb4eb0><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-synonym-graph-tokenfilter.html" target="_self" rel="noopener noreferrer" data-v-73cb4eb0>synonym_graph</a></li> <li data-v-73cb4eb0><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-word-delimiter-graph-tokenfilter.html" target="_self" rel="noopener noreferrer" data-v-73cb4eb0>word_delimiter_graph</a></li></ul></li> <li data-v-73cb4eb0>举例，domain name system 和它的同义词 dns，它们的 position 都是0，然而，dns 的 positionLength 是3，其他的 token 都是默认 positionLength 为1。</li></ul> <div style="display:flex;" data-v-73cb4eb0><img src="https://www.elastic.co/guide/en/elasticsearch/reference/7.9/images/analysis/token-graph-dns-synonym-ex.svg" alt="" align="left" style="zoom:100%;display:block;" data-v-73cb4eb0></div> <h4 id="_3）搜索中使用-token-graph" data-v-73cb4eb0><a href="#_3）搜索中使用-token-graph" class="header-anchor" data-v-73cb4eb0>#</a> 3）搜索中使用 token graph</h4> <ul data-v-73cb4eb0><li data-v-73cb4eb0>索引时，是会忽略 positionLength 信息，而且不支持包含横跨多个 position 的 token 的 token graph。</li> <li data-v-73cb4eb0>但是，查询时，例如 match、match_phrase，会从想要查询的字符串中生成多个 token graph （包括 multi_position tokens 的 graph），借此创建多个子查询。</li> <li data-v-73cb4eb0>举例，使用 match_phrase 查询：domain name system is fragile
<ul data-v-73cb4eb0><li data-v-73cb4eb0>在对搜索字符串进行文本分析时，domain name system 的同义词 dns 会被添加到查询文本的 token stream 中，dns 的 positionLength 是3,如下图</li> <li data-v-73cb4eb0>match_phrase 查询会使用这个 graph 生成多个子查询，这意味着匹配到的文档更加的全面。</li></ul></li></ul> <div style="display:flex;" data-v-73cb4eb0><img src="https://www.elastic.co/guide/en/elasticsearch/reference/7.9/images/analysis/token-graph-dns-synonym-ex.svg" alt="" align="left" style="zoom:100%;display:block;" data-v-73cb4eb0></div> <div class="language-json line-numbers-mode" data-v-73cb4eb0><pre class="language-json" data-v-73cb4eb0><code data-v-73cb4eb0>dns is fragile
domain name system is fragile
</code></pre> <div class="line-numbers-wrapper" data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>1</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>2</span><br data-v-73cb4eb0></div></div><h4 id="_4）invalid-token-graphs" data-v-73cb4eb0><a href="#_4）invalid-token-graphs" class="header-anchor" data-v-73cb4eb0>#</a> 4）Invalid token graphs</h4> <ul data-v-73cb4eb0><li data-v-73cb4eb0><p data-v-73cb4eb0>下面的 token filter 可以添加跨越多个位置的 token (如 dns)，但只记录默认的 positionLength 为1:</p> <ul data-v-73cb4eb0><li data-v-73cb4eb0><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-synonym-tokenfilter.html" target="_self" rel="noopener noreferrer" data-v-73cb4eb0>synonym</a></li> <li data-v-73cb4eb0><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-word-delimiter-tokenfilter.html" target="_self" rel="noopener noreferrer" data-v-73cb4eb0>word_delimiter</a></li></ul></li> <li data-v-73cb4eb0><p data-v-73cb4eb0>这意味着如果 token stream 包含 domain name system 这样的词组时，也会向 token stream 中添加同义词 token（dns），但是 dns 的 positionLength 是默认值 1，导致 token graph 是错误的；</p> <div style="display:flex;" data-v-73cb4eb0><img src="https://www.elastic.co/guide/en/elasticsearch/reference/7.9/images/analysis/token-graph-dns-invalid-ex.svg" alt="" align="left" style="zoom:100%;display:block;" data-v-73cb4eb0></div></li> <li data-v-73cb4eb0><p data-v-73cb4eb0>无效的 token graph 可能导致意外的搜索结果，要避免使用。</p></li></ul> <h2 id="_3-配置-text-analysis" data-v-73cb4eb0><a href="#_3-配置-text-analysis" class="header-anchor" data-v-73cb4eb0>#</a> 3. 配置 Text Analysis</h2> <ul data-v-73cb4eb0><li data-v-73cb4eb0>一般情况下，ES 提供的默认分析器 standard analyzer 可以满足大部分的使用需求；</li> <li data-v-73cb4eb0>如果一些内置的分析器也无法满足需求，可以使用 ES 提供的一些 option 选项功能来对 analyzer 进行微调</li> <li data-v-73cb4eb0>例如，给 standard analyzer 配置 stop words 的自定义移除列表；</li> <li data-v-73cb4eb0>最后就是，可以通过组合 analyzer 的底层模块来定制自己的分析器；</li></ul> <h3 id="_3-1-使用-analyzer-api-测试" data-v-73cb4eb0><a href="#_3-1-使用-analyzer-api-测试" class="header-anchor" data-v-73cb4eb0>#</a> 3.1 使用 Analyzer API 测试</h3> <h4 id="_1）测试内置的-analyzer：" data-v-73cb4eb0><a href="#_1）测试内置的-analyzer：" class="header-anchor" data-v-73cb4eb0>#</a> 1）测试内置的 Analyzer：</h4> <div class="language-json line-numbers-mode" data-v-73cb4eb0><pre class="language-json" data-v-73cb4eb0><code data-v-73cb4eb0>POST _analyze
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;whitespace&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
  <span class="token property" data-v-73cb4eb0>&quot;text&quot;</span><span class="token operator" data-v-73cb4eb0>:</span>     <span class="token string" data-v-73cb4eb0>&quot;The quick brown fox.&quot;</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>
</code></pre> <div class="line-numbers-wrapper" data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>1</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>2</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>3</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>4</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>5</span><br data-v-73cb4eb0></div></div><h4 id="_2）测试自定义组合模块" data-v-73cb4eb0><a href="#_2）测试自定义组合模块" class="header-anchor" data-v-73cb4eb0>#</a> 2）测试自定义组合模块</h4> <ul data-v-73cb4eb0><li data-v-73cb4eb0>也可以组合 tokenizer、character filter、token filter 来进行测试：
<ul data-v-73cb4eb0><li data-v-73cb4eb0>一个 tokenizer 分词器；</li> <li data-v-73cb4eb0>0 或多个 token filter；</li> <li data-v-73cb4eb0>0 或多个 character filter；</li></ul></li></ul> <div class="language-json line-numbers-mode" data-v-73cb4eb0><pre class="language-json" data-v-73cb4eb0><code data-v-73cb4eb0>POST _analyze
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;tokenizer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;standard&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
  <span class="token property" data-v-73cb4eb0>&quot;filter&quot;</span><span class="token operator" data-v-73cb4eb0>:</span>  <span class="token punctuation" data-v-73cb4eb0>[</span> <span class="token string" data-v-73cb4eb0>&quot;lowercase&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span> <span class="token string" data-v-73cb4eb0>&quot;asciifolding&quot;</span> <span class="token punctuation" data-v-73cb4eb0>]</span><span class="token punctuation" data-v-73cb4eb0>,</span>
  <span class="token property" data-v-73cb4eb0>&quot;text&quot;</span><span class="token operator" data-v-73cb4eb0>:</span>      <span class="token string" data-v-73cb4eb0>&quot;Is this déja vu?&quot;</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>
######返回结果
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;tokens&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>[</span>
    <span class="token punctuation" data-v-73cb4eb0>{</span>
      <span class="token property" data-v-73cb4eb0>&quot;token&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;is&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;start_offset&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token number" data-v-73cb4eb0>0</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;end_offset&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token number" data-v-73cb4eb0>2</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;type&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;&lt;ALPHANUM&gt;&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;position&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token number" data-v-73cb4eb0>0</span>
    <span class="token punctuation" data-v-73cb4eb0>}</span><span class="token punctuation" data-v-73cb4eb0>,</span>
    <span class="token punctuation" data-v-73cb4eb0>{</span>
      <span class="token property" data-v-73cb4eb0>&quot;token&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;this&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;start_offset&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token number" data-v-73cb4eb0>3</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;end_offset&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token number" data-v-73cb4eb0>7</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;type&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;&lt;ALPHANUM&gt;&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;position&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token number" data-v-73cb4eb0>1</span>
    <span class="token punctuation" data-v-73cb4eb0>}</span><span class="token punctuation" data-v-73cb4eb0>,</span>
    <span class="token punctuation" data-v-73cb4eb0>{</span>
      <span class="token property" data-v-73cb4eb0>&quot;token&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;deja&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;start_offset&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token number" data-v-73cb4eb0>8</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;end_offset&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token number" data-v-73cb4eb0>12</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;type&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;&lt;ALPHANUM&gt;&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;position&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token number" data-v-73cb4eb0>2</span>
    <span class="token punctuation" data-v-73cb4eb0>}</span><span class="token punctuation" data-v-73cb4eb0>,</span>
    <span class="token punctuation" data-v-73cb4eb0>{</span>
      <span class="token property" data-v-73cb4eb0>&quot;token&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;vu&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;start_offset&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token number" data-v-73cb4eb0>13</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;end_offset&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token number" data-v-73cb4eb0>15</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;type&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;&lt;ALPHANUM&gt;&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;position&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token number" data-v-73cb4eb0>3</span>
    <span class="token punctuation" data-v-73cb4eb0>}</span>
  <span class="token punctuation" data-v-73cb4eb0>]</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>
</code></pre> <div class="line-numbers-wrapper" data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>1</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>2</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>3</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>4</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>5</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>6</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>7</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>8</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>9</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>10</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>11</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>12</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>13</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>14</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>15</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>16</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>17</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>18</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>19</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>20</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>21</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>22</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>23</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>24</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>25</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>26</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>27</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>28</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>29</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>30</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>31</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>32</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>33</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>34</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>35</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>36</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>37</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>38</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>39</span><br data-v-73cb4eb0></div></div><blockquote data-v-73cb4eb0><ul data-v-73cb4eb0><li data-v-73cb4eb0>Analyzer 不仅将文本切分成了 tokens，还记录一些额外的信息：
<ul data-v-73cb4eb0><li data-v-73cb4eb0>每个 token 的顺序或相对位置：用于词组查询或者是同义词查询；</li> <li data-v-73cb4eb0>每个 token 在原始文本中的 start、end 字符的偏移量：用于搜索词命中的高亮显示处理；</li></ul></li></ul></blockquote> <h4 id="_3）测试自定义analyzer" data-v-73cb4eb0><a href="#_3）测试自定义analyzer" class="header-anchor" data-v-73cb4eb0>#</a> 3）测试自定义Analyzer</h4> <ul data-v-73cb4eb0><li data-v-73cb4eb0><p data-v-73cb4eb0>在一个索引中自定义一个 Analyzer，然后可以针对这个索引使用 Analyzer API 对 Custom Analyzer 进行测试：</p> <div class="language-json line-numbers-mode" data-v-73cb4eb0><pre class="language-json" data-v-73cb4eb0><code data-v-73cb4eb0># settings 中定义一个analyzer叫做std_folded
# mappings 中 my_text 字段使用这个自定义的 analyzer
PUT my_index
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;settings&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
    <span class="token property" data-v-73cb4eb0>&quot;analysis&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
      <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
        <span class="token property" data-v-73cb4eb0>&quot;std_folded&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span> 
          <span class="token property" data-v-73cb4eb0>&quot;type&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;custom&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
          <span class="token property" data-v-73cb4eb0>&quot;tokenizer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;standard&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
          <span class="token property" data-v-73cb4eb0>&quot;filter&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>[</span>
            <span class="token string" data-v-73cb4eb0>&quot;lowercase&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
            <span class="token string" data-v-73cb4eb0>&quot;asciifolding&quot;</span>
          <span class="token punctuation" data-v-73cb4eb0>]</span>
        <span class="token punctuation" data-v-73cb4eb0>}</span>
      <span class="token punctuation" data-v-73cb4eb0>}</span>
    <span class="token punctuation" data-v-73cb4eb0>}</span>
  <span class="token punctuation" data-v-73cb4eb0>}</span><span class="token punctuation" data-v-73cb4eb0>,</span>
  <span class="token property" data-v-73cb4eb0>&quot;mappings&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
    <span class="token property" data-v-73cb4eb0>&quot;properties&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
      <span class="token property" data-v-73cb4eb0>&quot;my_text&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
        <span class="token property" data-v-73cb4eb0>&quot;type&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;text&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
        <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;std_folded&quot;</span> 
      <span class="token punctuation" data-v-73cb4eb0>}</span>
    <span class="token punctuation" data-v-73cb4eb0>}</span>
  <span class="token punctuation" data-v-73cb4eb0>}</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>
# my_index索引中使用 _analyzer 测试方式<span class="token number" data-v-73cb4eb0>1</span>：通过analyzer名称
GET my_index/_analyze 
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;std_folded&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span> 
  <span class="token property" data-v-73cb4eb0>&quot;text&quot;</span><span class="token operator" data-v-73cb4eb0>:</span>     <span class="token string" data-v-73cb4eb0>&quot;Is this déjà vu?&quot;</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>
# my_index索引中使用 _analyzer 测试方式<span class="token number" data-v-73cb4eb0>2</span>：通过字段名，这个字段要在mappings中配置好使用自定义anaylzer
GET my_index/_analyze 
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;field&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;my_text&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span> 
  <span class="token property" data-v-73cb4eb0>&quot;text&quot;</span><span class="token operator" data-v-73cb4eb0>:</span>  <span class="token string" data-v-73cb4eb0>&quot;Is this déjà vu?&quot;</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>
</code></pre> <div class="line-numbers-wrapper" data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>1</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>2</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>3</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>4</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>5</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>6</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>7</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>8</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>9</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>10</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>11</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>12</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>13</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>14</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>15</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>16</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>17</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>18</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>19</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>20</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>21</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>22</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>23</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>24</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>25</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>26</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>27</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>28</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>29</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>30</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>31</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>32</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>33</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>34</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>35</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>36</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>37</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>38</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>39</span><br data-v-73cb4eb0></div></div></li></ul> <h3 id="_3-2-配置内置的-analyzer" data-v-73cb4eb0><a href="#_3-2-配置内置的-analyzer" class="header-anchor" data-v-73cb4eb0>#</a> 3.2 配置内置的 Analyzer</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0><p data-v-73cb4eb0><a href="/BigData/ELK/ES-TextAnalysis.html#内置-analyzer-详解" data-v-73cb4eb0><strong data-v-73cb4eb0>内置 Analyzer 详解</strong></a>；</p></li> <li data-v-73cb4eb0><p data-v-73cb4eb0>内置的 Analyzer 可以通过配置 options 选项参数来对分析器进行微调：</p> <div class="language-json line-numbers-mode" data-v-73cb4eb0><pre class="language-json" data-v-73cb4eb0><code data-v-73cb4eb0>PUT my_index
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;settings&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
    <span class="token property" data-v-73cb4eb0>&quot;analysis&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
      <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
        <span class="token property" data-v-73cb4eb0>&quot;std_english&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span> 
          <span class="token property" data-v-73cb4eb0>&quot;type&quot;</span><span class="token operator" data-v-73cb4eb0>:</span>      <span class="token string" data-v-73cb4eb0>&quot;standard&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
          <span class="token property" data-v-73cb4eb0>&quot;stopwords&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;_english_&quot;</span>
        <span class="token punctuation" data-v-73cb4eb0>}</span>
      <span class="token punctuation" data-v-73cb4eb0>}</span>
    <span class="token punctuation" data-v-73cb4eb0>}</span>
  <span class="token punctuation" data-v-73cb4eb0>}</span><span class="token punctuation" data-v-73cb4eb0>,</span>
  <span class="token property" data-v-73cb4eb0>&quot;mappings&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
    <span class="token property" data-v-73cb4eb0>&quot;properties&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
      <span class="token property" data-v-73cb4eb0>&quot;my_text&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
        <span class="token property" data-v-73cb4eb0>&quot;type&quot;</span><span class="token operator" data-v-73cb4eb0>:</span>     <span class="token string" data-v-73cb4eb0>&quot;text&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
        <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;standard&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span> 
        <span class="token property" data-v-73cb4eb0>&quot;fields&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
          <span class="token property" data-v-73cb4eb0>&quot;english&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
            <span class="token property" data-v-73cb4eb0>&quot;type&quot;</span><span class="token operator" data-v-73cb4eb0>:</span>     <span class="token string" data-v-73cb4eb0>&quot;text&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
            <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;std_english&quot;</span> 
          <span class="token punctuation" data-v-73cb4eb0>}</span>
        <span class="token punctuation" data-v-73cb4eb0>}</span>
      <span class="token punctuation" data-v-73cb4eb0>}</span>
    <span class="token punctuation" data-v-73cb4eb0>}</span>
  <span class="token punctuation" data-v-73cb4eb0>}</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>

POST my_index/_analyze
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;field&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;my_text&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span> 
  <span class="token property" data-v-73cb4eb0>&quot;text&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;The old brown cow&quot;</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>

POST my_index/_analyze
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;field&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;my_text.english&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span> 
  <span class="token property" data-v-73cb4eb0>&quot;text&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;The old brown cow&quot;</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>
</code></pre> <div class="line-numbers-wrapper" data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>1</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>2</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>3</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>4</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>5</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>6</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>7</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>8</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>9</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>10</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>11</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>12</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>13</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>14</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>15</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>16</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>17</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>18</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>19</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>20</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>21</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>22</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>23</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>24</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>25</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>26</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>27</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>28</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>29</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>30</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>31</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>32</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>33</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>34</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>35</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>36</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>37</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>38</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>39</span><br data-v-73cb4eb0></div></div><blockquote data-v-73cb4eb0><ul data-v-73cb4eb0><li data-v-73cb4eb0>在 standard analyzer 基础上定义了一个名为 std_english Analyzer，并为它配置上 ES 预定义的 english stopwords 移除列表；</li> <li data-v-73cb4eb0>my_text 字段使用 standard Analyzer 分词，不会移除 stopwords，结果：[ the, old, brown, cow ]；</li> <li data-v-73cb4eb0>my_text.english 子字段使用自定义的 std_english Analyzer，所以 English stopwords 会被移除，结果：[ old, brown, cow ]</li></ul></blockquote></li></ul> <h3 id="_3-3-配置自定义的-analyzer" data-v-73cb4eb0><a href="#_3-3-配置自定义的-analyzer" class="header-anchor" data-v-73cb4eb0>#</a> 3.3 配置自定义的 Analyzer</h3> <h4 id="_1）配置项" data-v-73cb4eb0><a href="#_1）配置项" class="header-anchor" data-v-73cb4eb0>#</a> 1）配置项</h4> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>tokenizer</strong>（必选项）：一个内置或者自定义的 tokenizer；</li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>char_filter</strong>（非必选）：0个或多个内置、自定义的 character filter 组成的数组；</li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>filter</strong>（非必选）：0个或多个内置、自定义的 token filter 组成的数据；</li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>position_increment_gap</strong>：默认值100。如果一个字段是由多个 text 组成的数组，那么在索引时，ES 会给 text元素之间插入一个假空隙，使得两个元素之间的 position 保持一个距离，以防止搜索词组时跨越多个元素进行匹配。<code data-v-73cb4eb0>可以在 Mappings 中为 text 字段修改 position_increment_gap 的值</code>。例如：
<ul data-v-73cb4eb0><li data-v-73cb4eb0>有字段值：[ &quot;John Abraham&quot;, &quot;Lincoln Smith&quot;]；</li> <li data-v-73cb4eb0>match_phrase 搜索：&quot;Abraham Lincoln&quot;；</li> <li data-v-73cb4eb0>因为 ES 在元素间插入了间隙，所以不会跨元素搜索，没有匹配的结果；</li> <li data-v-73cb4eb0>如果 match_phrase 添加参数 &quot;slop&quot;: 101，那么就会把整个数组的所有元素当作一个 text 去匹配，元素间的 position 没有间隙。会匹配到结果。</li></ul></li></ul> <h4 id="_2）一个比较复杂的例子" data-v-73cb4eb0><a href="#_2）一个比较复杂的例子" class="header-anchor" data-v-73cb4eb0>#</a> 2）一个比较复杂的例子</h4> <ul data-v-73cb4eb0><li data-v-73cb4eb0><p data-v-73cb4eb0><strong data-v-73cb4eb0>Character Filter</strong></p> <ul data-v-73cb4eb0><li data-v-73cb4eb0>自定义一个名称为 emoticons 的 Character Filter，其类型是 <code data-v-73cb4eb0>Mapping Character Filter</code>，将 &quot;😃&quot; 表情符转换为 &quot;<em data-v-73cb4eb0>happy</em>&quot;， &quot;😦&quot; 表情符转换为 &quot;<em data-v-73cb4eb0>sad</em>&quot;；</li></ul></li> <li data-v-73cb4eb0><p data-v-73cb4eb0><strong data-v-73cb4eb0>Tokenizer</strong></p> <ul data-v-73cb4eb0><li data-v-73cb4eb0>自定义一个名称为 punctuation 的 Tokenizer，其类型是 <code data-v-73cb4eb0>Pattern Tokenizer</code>，根据数组中的空格及标点符号 [ .,!?] 进行分词；</li></ul></li> <li data-v-73cb4eb0><p data-v-73cb4eb0><strong data-v-73cb4eb0>Token Filters</strong></p> <ul data-v-73cb4eb0><li data-v-73cb4eb0>内置的 <code data-v-73cb4eb0>Lowercase Token Filter</code></li> <li data-v-73cb4eb0>自定义一个名为 english_stop 的 Token Filter，其类型是 <code data-v-73cb4eb0>Stop Token Filter</code>, 使用 ES 预定义的 English stop words 移除列表；</li></ul></li></ul> <blockquote data-v-73cb4eb0><p data-v-73cb4eb0>字段值：&quot;I'm a 😃 person, and you?&quot;</p> <p data-v-73cb4eb0>分词结果：[ i'm, <em data-v-73cb4eb0>happy</em>, person, you ]</p></blockquote> <div class="language-json line-numbers-mode" data-v-73cb4eb0><pre class="language-json" data-v-73cb4eb0><code data-v-73cb4eb0>UT my_index
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;settings&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
    <span class="token property" data-v-73cb4eb0>&quot;analysis&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
      <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
        <span class="token property" data-v-73cb4eb0>&quot;my_custom_analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span> 
          <span class="token property" data-v-73cb4eb0>&quot;type&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;custom&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
          <span class="token property" data-v-73cb4eb0>&quot;char_filter&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>[</span>
            <span class="token string" data-v-73cb4eb0>&quot;emoticons&quot;</span>
          <span class="token punctuation" data-v-73cb4eb0>]</span><span class="token punctuation" data-v-73cb4eb0>,</span>
          <span class="token property" data-v-73cb4eb0>&quot;tokenizer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;punctuation&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
          <span class="token property" data-v-73cb4eb0>&quot;filter&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>[</span>
            <span class="token string" data-v-73cb4eb0>&quot;lowercase&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
            <span class="token string" data-v-73cb4eb0>&quot;english_stop&quot;</span>
          <span class="token punctuation" data-v-73cb4eb0>]</span>
        <span class="token punctuation" data-v-73cb4eb0>}</span>
      <span class="token punctuation" data-v-73cb4eb0>}</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;tokenizer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
        <span class="token property" data-v-73cb4eb0>&quot;punctuation&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span> 
          <span class="token property" data-v-73cb4eb0>&quot;type&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;pattern&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
          <span class="token property" data-v-73cb4eb0>&quot;pattern&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;[ .,!?]&quot;</span>
        <span class="token punctuation" data-v-73cb4eb0>}</span>
      <span class="token punctuation" data-v-73cb4eb0>}</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;char_filter&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
        <span class="token property" data-v-73cb4eb0>&quot;emoticons&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span> 
          <span class="token property" data-v-73cb4eb0>&quot;type&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;mapping&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
          <span class="token property" data-v-73cb4eb0>&quot;mappings&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>[</span>
            <span class="token string" data-v-73cb4eb0>&quot;:) =&gt; _happy_&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
            <span class="token string" data-v-73cb4eb0>&quot;:( =&gt; _sad_&quot;</span>
          <span class="token punctuation" data-v-73cb4eb0>]</span>
        <span class="token punctuation" data-v-73cb4eb0>}</span>
      <span class="token punctuation" data-v-73cb4eb0>}</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;filter&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
        <span class="token property" data-v-73cb4eb0>&quot;english_stop&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span> 
          <span class="token property" data-v-73cb4eb0>&quot;type&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;stop&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
          <span class="token property" data-v-73cb4eb0>&quot;stopwords&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;_english_&quot;</span>
        <span class="token punctuation" data-v-73cb4eb0>}</span>
      <span class="token punctuation" data-v-73cb4eb0>}</span>
    <span class="token punctuation" data-v-73cb4eb0>}</span>
  <span class="token punctuation" data-v-73cb4eb0>}</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>

POST my_index/_analyze
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;my_custom_analyzer&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
  <span class="token property" data-v-73cb4eb0>&quot;text&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;I'm a :) person, and you?&quot;</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>
</code></pre> <div class="line-numbers-wrapper" data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>1</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>2</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>3</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>4</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>5</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>6</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>7</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>8</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>9</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>10</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>11</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>12</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>13</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>14</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>15</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>16</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>17</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>18</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>19</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>20</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>21</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>22</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>23</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>24</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>25</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>26</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>27</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>28</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>29</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>30</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>31</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>32</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>33</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>34</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>35</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>36</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>37</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>38</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>39</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>40</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>41</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>42</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>43</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>44</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>45</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>46</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>47</span><br data-v-73cb4eb0></div></div><h3 id="_3-4-指定-analyzer" data-v-73cb4eb0><a href="#_3-4-指定-analyzer" class="header-anchor" data-v-73cb4eb0>#</a> 3.4 指定 Analyzer</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0>ES 提供了不同 level、不同场景下指定内置，或者自定义的 Analyzer：
<ul data-v-73cb4eb0><li data-v-73cb4eb0>字段、索引、查询 level；</li> <li data-v-73cb4eb0>索引时，查询时；</li></ul></li></ul> <blockquote data-v-73cb4eb0><ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>尽量保持简单</strong> <ul data-v-73cb4eb0><li data-v-73cb4eb0>虽然 ES 可以灵活的在不同 level、场景下指定 Analyzer，但是非必要的情况下不要这么做，尽量保持简单；</li> <li data-v-73cb4eb0>大多数情况下，最简单最好的方法：为每个 text 字段指定一个 Analyzer；</li> <li data-v-73cb4eb0>而且，ES 默认的 Analyzer 配置也很好，索引和搜索使用相同的 Analyzer；</li> <li data-v-73cb4eb0>可以使用 GET my_index/_mapping 查看字段具体使用的 Analyzer；</li></ul></li></ul></blockquote> <h4 id="_1）es-如何确定-index-的-analyzer" data-v-73cb4eb0><a href="#_1）es-如何确定-index-的-analyzer" class="header-anchor" data-v-73cb4eb0>#</a> 1）ES 如何确定 Index 的 Analyzer?</h4> <ul data-v-73cb4eb0><li data-v-73cb4eb0>ES 通过按顺序检查下面的参数，来确定索引时使用什么 Analyzer：
<ul data-v-73cb4eb0><li data-v-73cb4eb0>mappings 中字段的 analyzer 参数；</li> <li data-v-73cb4eb0>settings 中 analysis.analyzer.default 参数；</li> <li data-v-73cb4eb0>如果这些都没有设定，那么就使用默认的 standard analyzer；</li></ul></li></ul> <p data-v-73cb4eb0><strong data-v-73cb4eb0>(1) 为字段指定 Analyzer</strong></p> <div class="language-json line-numbers-mode" data-v-73cb4eb0><pre class="language-json" data-v-73cb4eb0><code data-v-73cb4eb0>PUT my_index
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;mappings&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
    <span class="token property" data-v-73cb4eb0>&quot;properties&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
      <span class="token property" data-v-73cb4eb0>&quot;title&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
        <span class="token property" data-v-73cb4eb0>&quot;type&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;text&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
        <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;whitespace&quot;</span>
      <span class="token punctuation" data-v-73cb4eb0>}</span>
    <span class="token punctuation" data-v-73cb4eb0>}</span>
  <span class="token punctuation" data-v-73cb4eb0>}</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>
</code></pre> <div class="line-numbers-wrapper" data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>1</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>2</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>3</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>4</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>5</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>6</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>7</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>8</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>9</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>10</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>11</span><br data-v-73cb4eb0></div></div><p data-v-73cb4eb0><strong data-v-73cb4eb0>(2) 为 Index 指定默认 Analyzer</strong></p> <div class="language-json line-numbers-mode" data-v-73cb4eb0><pre class="language-json" data-v-73cb4eb0><code data-v-73cb4eb0>UT my_index
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;settings&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
    <span class="token property" data-v-73cb4eb0>&quot;analysis&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
      <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
        <span class="token property" data-v-73cb4eb0>&quot;default&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
          <span class="token property" data-v-73cb4eb0>&quot;type&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;simple&quot;</span>
        <span class="token punctuation" data-v-73cb4eb0>}</span>
      <span class="token punctuation" data-v-73cb4eb0>}</span>
    <span class="token punctuation" data-v-73cb4eb0>}</span>
  <span class="token punctuation" data-v-73cb4eb0>}</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>
</code></pre> <div class="line-numbers-wrapper" data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>1</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>2</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>3</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>4</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>5</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>6</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>7</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>8</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>9</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>10</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>11</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>12</span><br data-v-73cb4eb0></div></div><h4 id="_2）es-如何确定-search-的-analyzer" data-v-73cb4eb0><a href="#_2）es-如何确定-search-的-analyzer" class="header-anchor" data-v-73cb4eb0>#</a> 2）ES 如何确定 Search 的 Analyzer?</h4> <blockquote data-v-73cb4eb0><ul data-v-73cb4eb0><li data-v-73cb4eb0>通常没必要在 Search 时指定一个与 Index 不同的 Analyzer
<ul data-v-73cb4eb0><li data-v-73cb4eb0>这样做，会对相关性造成负面的影响，导致预期外的搜索结果；</li> <li data-v-73cb4eb0>如果为 Search 单独指定了一个 Analyzer，官方建议在上线前对文本分析多进行测试。</li></ul></li></ul></blockquote> <ul data-v-73cb4eb0><li data-v-73cb4eb0>ES 通过按顺序检查下面的参数，来确定搜索时使用什么 Analyzer：
<ul data-v-73cb4eb0><li data-v-73cb4eb0>search query 中的 analyzer 参数；</li> <li data-v-73cb4eb0>mappings 中字段的 search_analyzer 参数；</li> <li data-v-73cb4eb0>settings 中 analysis.analyzer.default_search 参数；</li> <li data-v-73cb4eb0>mappings 中字段的 analyzer 参数；</li> <li data-v-73cb4eb0>如果这些都没有设定，那么就使用默认的 standard analyzer；</li></ul></li></ul> <p data-v-73cb4eb0><strong data-v-73cb4eb0>(1) 为 query 指定 Search Analyzer</strong></p> <p data-v-73cb4eb0><strong data-v-73cb4eb0>(2) 为字段指定 Search Analyzer</strong></p> <blockquote data-v-73cb4eb0><p data-v-73cb4eb0>如果在 mappings 中为字段配置了 search_analyzer，那么该字段的 analyzer 也必须配置；</p></blockquote> <p data-v-73cb4eb0><strong data-v-73cb4eb0>(3) 为 Index 指定 default Search Analyzer</strong></p> <blockquote data-v-73cb4eb0><p data-v-73cb4eb0>如果在 settings 中指定了索引的默认 Search Analyzer，那么 settings 中的 analysis.analyzer.default 也必须设置；</p></blockquote> <br data-v-73cb4eb0> <br data-v-73cb4eb0> <h2 id="内置-analyzer-详解" data-v-73cb4eb0><a href="#内置-analyzer-详解" class="header-anchor" data-v-73cb4eb0>#</a> 内置 Analyzer 详解</h2> <h3 id="_1-fingerprint-analyzer" data-v-73cb4eb0><a href="#_1-fingerprint-analyzer" class="header-anchor" data-v-73cb4eb0>#</a> 1. Fingerprint analyzer</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0><p data-v-73cb4eb0>Fingerprint analyzer 实现了 fingerprinting 算法 (OpenRefine项目中使用)。</p></li> <li data-v-73cb4eb0><p data-v-73cb4eb0>使用该 analyzer 场景下，文本会被转为小写格式，经过规范化 (normalize) 处理之后移除扩展字符，然后再经过排序，删除重复数据组合为单个 token；如果配置了停用词，则停用词也将会被移除。</p></li> <li data-v-73cb4eb0><p data-v-73cb4eb0><strong data-v-73cb4eb0>底层组成模块：</strong></p> <ul data-v-73cb4eb0><li data-v-73cb4eb0>Tokenizer：Standard Tokenizer；</li> <li data-v-73cb4eb0>Token Filters：
<ul data-v-73cb4eb0><li data-v-73cb4eb0>Lower Case Token Filter</li> <li data-v-73cb4eb0>ASCII folding</li> <li data-v-73cb4eb0>Stop Token Filter ( 默认未开启 )</li> <li data-v-73cb4eb0>Fingerprint</li></ul></li></ul></li> <li data-v-73cb4eb0><p data-v-73cb4eb0><strong data-v-73cb4eb0>可配置参数：</strong></p></li></ul> <table data-v-73cb4eb0><thead data-v-73cb4eb0><tr data-v-73cb4eb0><th data-v-73cb4eb0><strong data-v-73cb4eb0>参数</strong></th> <th data-v-73cb4eb0><strong data-v-73cb4eb0>参数说明</strong></th></tr></thead> <tbody data-v-73cb4eb0><tr data-v-73cb4eb0><td data-v-73cb4eb0>separator</td> <td data-v-73cb4eb0>连接多个词(term)的字符，默认为空格</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>max_output_size</td> <td data-v-73cb4eb0>token 允许的最大值,超过该值将直接被丢弃，默认值为255</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>stopwords</td> <td data-v-73cb4eb0>预定义的停用词，可以为0个或多个，例如 <em data-v-73cb4eb0>english</em> 或停用词数组，默认值为_none_</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>stopwords_path</td> <td data-v-73cb4eb0>停用词文件路径</td></tr></tbody></table> <ul data-v-73cb4eb0><li data-v-73cb4eb0><p data-v-73cb4eb0><strong data-v-73cb4eb0>举个例子：</strong></p> <div class="language-json line-numbers-mode" data-v-73cb4eb0><pre class="language-json" data-v-73cb4eb0><code data-v-73cb4eb0>#配置索引默认Analyzer，移除english停用词列表中的词
PUT my_index
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;settings&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
    <span class="token property" data-v-73cb4eb0>&quot;analysis&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
      <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
        <span class="token property" data-v-73cb4eb0>&quot;my_fingerprint_analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
          <span class="token property" data-v-73cb4eb0>&quot;type&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;fingerprint&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
          <span class="token property" data-v-73cb4eb0>&quot;stopwords&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;_english_&quot;</span>
        <span class="token punctuation" data-v-73cb4eb0>}</span>
      <span class="token punctuation" data-v-73cb4eb0>}</span>
    <span class="token punctuation" data-v-73cb4eb0>}</span>
  <span class="token punctuation" data-v-73cb4eb0>}</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>

POST my_index/_analyze
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;my_fingerprint_analyzer&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
  <span class="token property" data-v-73cb4eb0>&quot;text&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;Yes yes, Gödel said this sentence is consistent and.&quot;</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>
#######文本处理后是一个去重、排序、小写化、移除扩展符和stopword的单个token
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;tokens&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>[</span>
    <span class="token punctuation" data-v-73cb4eb0>{</span>
      <span class="token property" data-v-73cb4eb0>&quot;token&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;consistent godel said sentence yes&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;start_offset&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token number" data-v-73cb4eb0>0</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;end_offset&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token number" data-v-73cb4eb0>52</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;type&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;fingerprint&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;position&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token number" data-v-73cb4eb0>0</span>
    <span class="token punctuation" data-v-73cb4eb0>}</span>
  <span class="token punctuation" data-v-73cb4eb0>]</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>
</code></pre> <div class="line-numbers-wrapper" data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>1</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>2</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>3</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>4</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>5</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>6</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>7</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>8</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>9</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>10</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>11</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>12</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>13</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>14</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>15</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>16</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>17</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>18</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>19</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>20</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>21</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>22</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>23</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>24</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>25</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>26</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>27</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>28</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>29</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>30</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>31</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>32</span><br data-v-73cb4eb0></div></div></li> <li data-v-73cb4eb0><p data-v-73cb4eb0>如果通过配置参数来微调 Fingerprint Analyzer 已经满足不了需求的话，可以通过组合底层模块来重建一个类似 Fingerprint 的自定义 Analyzer，通常可以靠添加 token filter 来改变它；</p> <div class="language-json line-numbers-mode" data-v-73cb4eb0><pre class="language-json" data-v-73cb4eb0><code data-v-73cb4eb0>PUT /fingerprint_example
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;settings&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
    <span class="token property" data-v-73cb4eb0>&quot;analysis&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
      <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
        <span class="token property" data-v-73cb4eb0>&quot;rebuilt_fingerprint&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
          <span class="token property" data-v-73cb4eb0>&quot;tokenizer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;standard&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
          <span class="token property" data-v-73cb4eb0>&quot;filter&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>[</span>
            <span class="token string" data-v-73cb4eb0>&quot;lowercase&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
            <span class="token string" data-v-73cb4eb0>&quot;asciifolding&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
            <span class="token string" data-v-73cb4eb0>&quot;fingerprint&quot;</span>
          <span class="token punctuation" data-v-73cb4eb0>]</span>
        <span class="token punctuation" data-v-73cb4eb0>}</span>
      <span class="token punctuation" data-v-73cb4eb0>}</span>
    <span class="token punctuation" data-v-73cb4eb0>}</span>
  <span class="token punctuation" data-v-73cb4eb0>}</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>
</code></pre> <div class="line-numbers-wrapper" data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>1</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>2</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>3</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>4</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>5</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>6</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>7</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>8</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>9</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>10</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>11</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>12</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>13</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>14</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>15</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>16</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>17</span><br data-v-73cb4eb0></div></div></li></ul> <h3 id="_2-keyword-analyzer" data-v-73cb4eb0><a href="#_2-keyword-analyzer" class="header-anchor" data-v-73cb4eb0>#</a> 2. Keyword analyzer</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0>Keyword analyzer 视字符串为一个整体不进行分词处理；</li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>底层组成模块：</strong> <ul data-v-73cb4eb0><li data-v-73cb4eb0>Tokenizer：Keyword Tokenizer</li></ul></li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>没有可配置参数</strong></li> <li data-v-73cb4eb0>也可以重建 keyword analyzer，通过添加 token filter 来定制需求：</li></ul> <div class="language-json line-numbers-mode" data-v-73cb4eb0><pre class="language-json" data-v-73cb4eb0><code data-v-73cb4eb0>PUT /keyword_example
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;settings&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
    <span class="token property" data-v-73cb4eb0>&quot;analysis&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
      <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
        <span class="token property" data-v-73cb4eb0>&quot;rebuilt_keyword&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
          <span class="token property" data-v-73cb4eb0>&quot;tokenizer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;keyword&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
          <span class="token property" data-v-73cb4eb0>&quot;filter&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>[</span><span class="token punctuation" data-v-73cb4eb0>]</span>
        <span class="token punctuation" data-v-73cb4eb0>}</span>
      <span class="token punctuation" data-v-73cb4eb0>}</span>
    <span class="token punctuation" data-v-73cb4eb0>}</span>
  <span class="token punctuation" data-v-73cb4eb0>}</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>
</code></pre> <div class="line-numbers-wrapper" data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>1</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>2</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>3</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>4</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>5</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>6</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>7</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>8</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>9</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>10</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>11</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>12</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>13</span><br data-v-73cb4eb0></div></div><h3 id="_3-language-analyzer" data-v-73cb4eb0><a href="#_3-language-analyzer" class="header-anchor" data-v-73cb4eb0>#</a> 3. Language analyzer</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0>Language analyzer 是特定类型语言的分词器，支持以下语系：支持以下类型：阿拉伯语、亚美尼亚语、巴斯克语、孟加拉语、巴西语、保加利亚语、加泰罗尼亚语、中日韩语、捷克语、丹麦语、荷兰语、英语、爱沙尼亚语、芬兰语、法语、加利西亚语、德语、希腊语、印地语、匈牙利语、印度尼西亚语、爱尔兰语、意大利语、拉脱维亚语、立陶宛语、挪威语、波斯语、葡萄牙语、罗马尼亚语、俄语、索拉尼语、西班牙语、瑞典语、土耳其语、泰语。</li> <li data-v-73cb4eb0>可配置参数：</li></ul> <table data-v-73cb4eb0><thead data-v-73cb4eb0><tr data-v-73cb4eb0><th data-v-73cb4eb0><strong data-v-73cb4eb0>参数</strong></th> <th data-v-73cb4eb0><strong data-v-73cb4eb0>参数说明</strong></th></tr></thead> <tbody data-v-73cb4eb0><tr data-v-73cb4eb0><td data-v-73cb4eb0>stopwords</td> <td data-v-73cb4eb0>ES 内部预定义的停用词，可以为0个或多个，例如 <em data-v-73cb4eb0>english</em> 或自定义的stopword 数组</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>stopwords_path</td> <td data-v-73cb4eb0>使用外部的 stopwords 文件</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>stem_exclusion</td> <td data-v-73cb4eb0>部分语言支持在词干提取时忽略一组小写格式的单词列表</td></tr></tbody></table> <ul data-v-73cb4eb0><li data-v-73cb4eb0>重建 Language analyzer，例如，如果你不想做词干转化（相当于 stem_exclusion），那么就可以在自定义 Analyzer 中移除 keyword_marker token filter；</li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>举例：</strong> <ul data-v-73cb4eb0><li data-v-73cb4eb0>english analyze
<ul data-v-73cb4eb0><li data-v-73cb4eb0>自定义的 token filter 中，english_keywords 一般不要使用，除非你想把其中的单词不做词干分析处理；</li></ul></li></ul></li></ul> <h3 id="_4-pattern-analyzer" data-v-73cb4eb0><a href="#_4-pattern-analyzer" class="header-anchor" data-v-73cb4eb0>#</a> 4. Pattern analyzer</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0>Pattern analyzer 使用正则表达式作为文本分词规则；</li> <li data-v-73cb4eb0>注意：正则表达式匹配的应该是 token 分隔符，而不是去匹配 token 本身，<code data-v-73cb4eb0>默认正则为 \W+ (匹配非单词字符)</code>；</li> <li data-v-73cb4eb0>Pattern analyzer 使用的是 Java 正则表达式；</li> <li data-v-73cb4eb0>注意：糟糕的正则表达式可能会运行的很慢，甚至会抛出异常并导致运行终止；</li></ul> <br data-v-73cb4eb0> <ul data-v-73cb4eb0><li data-v-73cb4eb0><p data-v-73cb4eb0><strong data-v-73cb4eb0>底层模块组成：</strong></p> <ul data-v-73cb4eb0><li data-v-73cb4eb0>Tokenizer：Pattern Tokenizer；</li> <li data-v-73cb4eb0>Token Filter：
<ul data-v-73cb4eb0><li data-v-73cb4eb0>Lower Case Token Filter;</li> <li data-v-73cb4eb0>Stop Token Filter；(默认未启用)</li></ul></li></ul></li> <li data-v-73cb4eb0><p data-v-73cb4eb0>重建 Pattern Analyzer：</p></li> <li data-v-73cb4eb0><p data-v-73cb4eb0>可配置参数：</p></li></ul> <table data-v-73cb4eb0><thead data-v-73cb4eb0><tr data-v-73cb4eb0><th data-v-73cb4eb0><strong data-v-73cb4eb0>参数</strong></th> <th data-v-73cb4eb0><strong data-v-73cb4eb0>参数说明</strong></th></tr></thead> <tbody data-v-73cb4eb0><tr data-v-73cb4eb0><td data-v-73cb4eb0>pattern</td> <td data-v-73cb4eb0>java正则表达式，默认为 \W+</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>flags</td> <td data-v-73cb4eb0>java正则当中的 flags，flags应该用 | 分割，如&quot;CASE_INSENSITIVE|COMMENTS&quot;</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>lowercase</td> <td data-v-73cb4eb0>分隔出的词(term)是否以小写形式表示，默认为true</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>stopwords</td> <td data-v-73cb4eb0>预定义的停用词，可以为0个或多个，例如_english_或数组类型值，默认值为_none_</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>stopwords_path</td> <td data-v-73cb4eb0>停用词外部文件路径</td></tr></tbody></table> <ul data-v-73cb4eb0><li data-v-73cb4eb0>举例：
<ul data-v-73cb4eb0><li data-v-73cb4eb0>简单例子：正则匹配 非单词 或 &quot;_&quot; 作为分隔符来切分单词，并且转化小写；
<ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>注意：</strong><code data-v-73cb4eb0>正则表达式在 JSON 字符串中，反斜杠 &quot;\&quot; 需要用转义字符</code>；</li></ul></li> <li data-v-73cb4eb0>复杂例子：将文本以驼峰命名的规则进行切分单词；
<ul data-v-73cb4eb0><li data-v-73cb4eb0>正则表达式解释说明：</li></ul></li></ul></li></ul> <h3 id="_5-simple-analyzer" data-v-73cb4eb0><a href="#_5-simple-analyzer" class="header-anchor" data-v-73cb4eb0>#</a> 5. Simple analyzer</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0>Simple analyzer 是根据非字母字符（如数字、空格、连字符和撇号）对文本进行拆分，且将处理的所有关 token 转换成小写格式</li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>无可配置参数</strong></li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>底层模块组成：</strong> <ul data-v-73cb4eb0><li data-v-73cb4eb0>Tokenizer：Lowercase Tokenizer；</li></ul></li> <li data-v-73cb4eb0>重建 Simple analyzer：根据需求添加 token filter；</li></ul> <h3 id="_6-standard-analyzer" data-v-73cb4eb0><a href="#_6-standard-analyzer" class="header-anchor" data-v-73cb4eb0>#</a> 6. Standard analyzer</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0>Standard analyzer 是 ES 默认的 analyzer，它提供了基于语法的切分词处理（基于 Unicode 文本分割算法），并且适用于大多数语言。</li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>可配置参数：</strong></li></ul> <table data-v-73cb4eb0><thead data-v-73cb4eb0><tr data-v-73cb4eb0><th data-v-73cb4eb0><strong data-v-73cb4eb0>参数</strong></th> <th data-v-73cb4eb0><strong data-v-73cb4eb0>参数说明</strong></th></tr></thead> <tbody data-v-73cb4eb0><tr data-v-73cb4eb0><td data-v-73cb4eb0>max_token_length</td> <td data-v-73cb4eb0>token 最大长度，如果超过此长度的 token，则按照最大长度再次拆分，默认值255</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>stopwords</td> <td data-v-73cb4eb0>预定义的停用词，可以为0个或多个，例如_english_或数组类型值，默认值为_none_</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>stopwords_path</td> <td data-v-73cb4eb0>停用词外部文件路径</td></tr></tbody></table> <ul data-v-73cb4eb0><li data-v-73cb4eb0><p data-v-73cb4eb0><strong data-v-73cb4eb0>底层模块组成：</strong></p> <ul data-v-73cb4eb0><li data-v-73cb4eb0>Tokenizer：Standard Tokenizer；</li> <li data-v-73cb4eb0>Token filter：
<ul data-v-73cb4eb0><li data-v-73cb4eb0>Lowercase Token filter；</li> <li data-v-73cb4eb0>Stop Token filter；（默认未启用）</li></ul></li></ul></li> <li data-v-73cb4eb0><p data-v-73cb4eb0><strong data-v-73cb4eb0>举例：</strong></p></li></ul> <h3 id="_7-stop-analyzer" data-v-73cb4eb0><a href="#_7-stop-analyzer" class="header-anchor" data-v-73cb4eb0>#</a> 7. Stop analyzer</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0>stop analyzer 与 simple analyzer 功能一样，不同之处在于支持停用词，默认情况下使用 <em data-v-73cb4eb0>english</em> 停用词；</li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>可配置参数：</strong></li></ul> <table data-v-73cb4eb0><thead data-v-73cb4eb0><tr data-v-73cb4eb0><th data-v-73cb4eb0><strong data-v-73cb4eb0>参数</strong></th> <th data-v-73cb4eb0><strong data-v-73cb4eb0>参数说明</strong></th></tr></thead> <tbody data-v-73cb4eb0><tr data-v-73cb4eb0><td data-v-73cb4eb0>stopwords</td> <td data-v-73cb4eb0>预定义的停用词，可以为0个或多个，例如_english_或数组类型值，默认值为_none_</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>stopwords_path</td> <td data-v-73cb4eb0>停用词外部文件路径</td></tr></tbody></table> <ul data-v-73cb4eb0><li data-v-73cb4eb0><p data-v-73cb4eb0><strong data-v-73cb4eb0>底层模块组成：</strong></p> <ul data-v-73cb4eb0><li data-v-73cb4eb0>Tokenizer：Lowercase Tokenizer；</li> <li data-v-73cb4eb0>Token filter：Stop Token filter；</li></ul></li> <li data-v-73cb4eb0><p data-v-73cb4eb0><strong data-v-73cb4eb0>举例：</strong></p></li></ul> <h3 id="_8-whitespace-analyzer" data-v-73cb4eb0><a href="#_8-whitespace-analyzer" class="header-anchor" data-v-73cb4eb0>#</a> 8. Whitespace analyzer</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0>Whitespace analyzer 根据空白字符将文本拆分；</li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>没有可配置参数</strong></li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>底层模块组成：</strong> <ul data-v-73cb4eb0><li data-v-73cb4eb0>Tokenizer：Whitespace Tokenizer；</li></ul></li> <li data-v-73cb4eb0>重建：</li></ul> <br data-v-73cb4eb0> <br data-v-73cb4eb0> <h2 id="内置-character-filter-详解" data-v-73cb4eb0><a href="#内置-character-filter-详解" class="header-anchor" data-v-73cb4eb0>#</a> 内置 Character filter 详解</h2> <h3 id="_1-html-strip-character-filter" data-v-73cb4eb0><a href="#_1-html-strip-character-filter" class="header-anchor" data-v-73cb4eb0>#</a> 1. HTML strip character filter</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>html_strip</strong>，从文本中剥离 HTML 元素并用其解码值替换HTML实体（例如，用 &amp;amp 替换 &amp;）。</li> <li data-v-73cb4eb0>可选参数：</li></ul> <table data-v-73cb4eb0><thead data-v-73cb4eb0><tr data-v-73cb4eb0><th data-v-73cb4eb0><strong data-v-73cb4eb0>参数</strong></th> <th data-v-73cb4eb0><strong data-v-73cb4eb0>参数说明</strong></th></tr></thead> <tbody data-v-73cb4eb0><tr data-v-73cb4eb0><td data-v-73cb4eb0>escaped_tags</td> <td data-v-73cb4eb0>（可选，字符串数组）不带尖括号（&lt;&gt;）的HTML元素数组。当从文本中剥离HTML时，过滤器将跳过这些HTML元素。例如，[&quot;p&quot;]值跳过&lt; p &gt;HTML元素。</td></tr></tbody></table> <div class="language-json line-numbers-mode" data-v-73cb4eb0><pre class="language-json" data-v-73cb4eb0><code data-v-73cb4eb0>PUT my_index
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;settings&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
    <span class="token property" data-v-73cb4eb0>&quot;analysis&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
      <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
        <span class="token property" data-v-73cb4eb0>&quot;my_analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
          <span class="token property" data-v-73cb4eb0>&quot;tokenizer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;keyword&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
          <span class="token property" data-v-73cb4eb0>&quot;char_filter&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>[</span>
            <span class="token string" data-v-73cb4eb0>&quot;my_custom_html_strip_char_filter&quot;</span>
          <span class="token punctuation" data-v-73cb4eb0>]</span>
        <span class="token punctuation" data-v-73cb4eb0>}</span>
      <span class="token punctuation" data-v-73cb4eb0>}</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;char_filter&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
        <span class="token property" data-v-73cb4eb0>&quot;my_custom_html_strip_char_filter&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
          <span class="token property" data-v-73cb4eb0>&quot;type&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;html_strip&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
          <span class="token property" data-v-73cb4eb0>&quot;escaped_tags&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>[</span>
            <span class="token string" data-v-73cb4eb0>&quot;b&quot;</span>
          <span class="token punctuation" data-v-73cb4eb0>]</span>
        <span class="token punctuation" data-v-73cb4eb0>}</span>
      <span class="token punctuation" data-v-73cb4eb0>}</span>
    <span class="token punctuation" data-v-73cb4eb0>}</span>
  <span class="token punctuation" data-v-73cb4eb0>}</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>

GET my_index/_analyze
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;my_analyzer&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
  <span class="token property" data-v-73cb4eb0>&quot;text&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;&lt;p&gt;I&amp;apos;m so &lt;b&gt;happy&lt;/b&gt;!&lt;/p&gt;&quot;</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>
#结果：<span class="token punctuation" data-v-73cb4eb0>[</span> \nI'm so &lt;b&gt;happy&lt;/b&gt;!\n <span class="token punctuation" data-v-73cb4eb0>]</span>
</code></pre> <div class="line-numbers-wrapper" data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>1</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>2</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>3</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>4</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>5</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>6</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>7</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>8</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>9</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>10</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>11</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>12</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>13</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>14</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>15</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>16</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>17</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>18</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>19</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>20</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>21</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>22</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>23</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>24</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>25</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>26</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>27</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>28</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>29</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>30</span><br data-v-73cb4eb0></div></div><h3 id="_2-mapping-character-filter" data-v-73cb4eb0><a href="#_2-mapping-character-filter" class="header-anchor" data-v-73cb4eb0>#</a> 2. Mapping character filter</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>mapping</strong>，接受键和值的映射。每当遇到与键相同的字符串时，它会用与该键关联的值替换它们。</li> <li data-v-73cb4eb0>使用的贪婪匹配；</li> <li data-v-73cb4eb0>允许替换成空字符串；</li> <li data-v-73cb4eb0>可选参数：
<ul data-v-73cb4eb0><li data-v-73cb4eb0>必须指定此 mappings 或 mappings_path 参数</li></ul></li></ul> <table data-v-73cb4eb0><thead data-v-73cb4eb0><tr data-v-73cb4eb0><th data-v-73cb4eb0><strong data-v-73cb4eb0>参数</strong></th> <th data-v-73cb4eb0><strong data-v-73cb4eb0>参数说明</strong></th></tr></thead> <tbody data-v-73cb4eb0><tr data-v-73cb4eb0><td data-v-73cb4eb0>mappings</td> <td data-v-73cb4eb0>（必需*，字符串数组）映射数组，每个元素的格式为key=&gt;value。</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>mappings_path</td> <td data-v-73cb4eb0>（必需*，字符串）包含键=&gt;值映射的文件的路径。此路径必须是相对于配置位置的绝对路径或相对路径，并且文件必须是UTF-8编码的。文件中的每个映射都必须用换行符分隔。</td></tr></tbody></table> <div class="language-json line-numbers-mode" data-v-73cb4eb0><pre class="language-json" data-v-73cb4eb0><code data-v-73cb4eb0>PUT /my_index
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;settings&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
    <span class="token property" data-v-73cb4eb0>&quot;analysis&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
      <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
        <span class="token property" data-v-73cb4eb0>&quot;my_analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
          <span class="token property" data-v-73cb4eb0>&quot;tokenizer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;standard&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
          <span class="token property" data-v-73cb4eb0>&quot;char_filter&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>[</span>
            <span class="token string" data-v-73cb4eb0>&quot;my_mappings_char_filter&quot;</span>
          <span class="token punctuation" data-v-73cb4eb0>]</span>
        <span class="token punctuation" data-v-73cb4eb0>}</span>
      <span class="token punctuation" data-v-73cb4eb0>}</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;char_filter&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
        <span class="token property" data-v-73cb4eb0>&quot;my_mappings_char_filter&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
          <span class="token property" data-v-73cb4eb0>&quot;type&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;mapping&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
          <span class="token property" data-v-73cb4eb0>&quot;mappings&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>[</span>
            <span class="token string" data-v-73cb4eb0>&quot;:) =&gt; _happy_&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
            <span class="token string" data-v-73cb4eb0>&quot;:( =&gt; _sad_&quot;</span>
          <span class="token punctuation" data-v-73cb4eb0>]</span>
        <span class="token punctuation" data-v-73cb4eb0>}</span>
      <span class="token punctuation" data-v-73cb4eb0>}</span>
    <span class="token punctuation" data-v-73cb4eb0>}</span>
  <span class="token punctuation" data-v-73cb4eb0>}</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>

GET /my_index/_analyze
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;tokenizer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;keyword&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
  <span class="token property" data-v-73cb4eb0>&quot;char_filter&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>[</span> <span class="token string" data-v-73cb4eb0>&quot;my_mappings_char_filter&quot;</span> <span class="token punctuation" data-v-73cb4eb0>]</span><span class="token punctuation" data-v-73cb4eb0>,</span>
  <span class="token property" data-v-73cb4eb0>&quot;text&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;I'm delighted about it :(&quot;</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>
#结果：<span class="token punctuation" data-v-73cb4eb0>[</span> I'm delighted about it _sad_ <span class="token punctuation" data-v-73cb4eb0>]</span>
</code></pre> <div class="line-numbers-wrapper" data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>1</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>2</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>3</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>4</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>5</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>6</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>7</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>8</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>9</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>10</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>11</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>12</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>13</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>14</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>15</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>16</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>17</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>18</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>19</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>20</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>21</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>22</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>23</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>24</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>25</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>26</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>27</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>28</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>29</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>30</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>31</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>32</span><br data-v-73cb4eb0></div></div><h3 id="_3-pattern-replace-character-filter" data-v-73cb4eb0><a href="#_3-pattern-replace-character-filter" class="header-anchor" data-v-73cb4eb0>#</a> 3. Pattern replace character filter</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>pattern_replace</strong>，使用正则表达式匹配应替换为指定替换字符串的字符；
<ul data-v-73cb4eb0><li data-v-73cb4eb0>替换字符串可以引用正则表达式中的捕获组。</li></ul></li> <li data-v-73cb4eb0>使用 Java 正则表达式；</li> <li data-v-73cb4eb0>写得不好的正则表达式可能运行得非常慢，甚至会抛出 StackOverflowError 并导致运行它的节点突然退出。</li> <li data-v-73cb4eb0>可选参数：</li></ul> <table data-v-73cb4eb0><thead data-v-73cb4eb0><tr data-v-73cb4eb0><th data-v-73cb4eb0><strong data-v-73cb4eb0>参数</strong></th> <th data-v-73cb4eb0><strong data-v-73cb4eb0>参数说明</strong></th></tr></thead> <tbody data-v-73cb4eb0><tr data-v-73cb4eb0><td data-v-73cb4eb0>pattern</td> <td data-v-73cb4eb0>Java 正则表达式</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>replacement</td> <td data-v-73cb4eb0>替换字符串，它可以使用$1..$9语法引用捕获组</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>flags</td> <td data-v-73cb4eb0>Java 正则表达式中的 flags，例如 &quot;CASE_INSENSITIVE|COMMENTS&quot;</td></tr></tbody></table> <ul data-v-73cb4eb0><li data-v-73cb4eb0>举例：123-456-789 → 123_456_789</li></ul> <div class="language-json line-numbers-mode" data-v-73cb4eb0><pre class="language-json" data-v-73cb4eb0><code data-v-73cb4eb0># (?=pattern)正向肯定匹配，<span class="token string" data-v-73cb4eb0>&quot;Windows(?=95|98|NT|2000)&quot;</span>能匹配<span class="token string" data-v-73cb4eb0>&quot;Windows2000&quot;</span>中的<span class="token string" data-v-73cb4eb0>&quot;Windows&quot;</span>，
# 但不能匹配<span class="token string" data-v-73cb4eb0>&quot;Windows3.1&quot;</span>中的<span class="token string" data-v-73cb4eb0>&quot;Windows&quot;</span>。
PUT my_index
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;settings&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
    <span class="token property" data-v-73cb4eb0>&quot;analysis&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
      <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
        <span class="token property" data-v-73cb4eb0>&quot;my_analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
          <span class="token property" data-v-73cb4eb0>&quot;tokenizer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;standard&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
          <span class="token property" data-v-73cb4eb0>&quot;char_filter&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>[</span>
            <span class="token string" data-v-73cb4eb0>&quot;my_char_filter&quot;</span>
          <span class="token punctuation" data-v-73cb4eb0>]</span>
        <span class="token punctuation" data-v-73cb4eb0>}</span>
      <span class="token punctuation" data-v-73cb4eb0>}</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;char_filter&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
        <span class="token property" data-v-73cb4eb0>&quot;my_char_filter&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
          <span class="token property" data-v-73cb4eb0>&quot;type&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;pattern_replace&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
          <span class="token property" data-v-73cb4eb0>&quot;pattern&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;(\\d+)-(?=\\d)&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
          <span class="token property" data-v-73cb4eb0>&quot;replacement&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;$1_&quot;</span>
        <span class="token punctuation" data-v-73cb4eb0>}</span>
      <span class="token punctuation" data-v-73cb4eb0>}</span>
    <span class="token punctuation" data-v-73cb4eb0>}</span>
  <span class="token punctuation" data-v-73cb4eb0>}</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>

POST my_index/_analyze
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;my_analyzer&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
  <span class="token property" data-v-73cb4eb0>&quot;text&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;My credit card is 123-456-789&quot;</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>
#结果：<span class="token punctuation" data-v-73cb4eb0>[</span> My<span class="token punctuation" data-v-73cb4eb0>,</span> credit<span class="token punctuation" data-v-73cb4eb0>,</span> card<span class="token punctuation" data-v-73cb4eb0>,</span> is<span class="token punctuation" data-v-73cb4eb0>,</span> <span class="token number" data-v-73cb4eb0>123</span>_<span class="token number" data-v-73cb4eb0>456</span>_<span class="token number" data-v-73cb4eb0>789</span> <span class="token punctuation" data-v-73cb4eb0>]</span>
</code></pre> <div class="line-numbers-wrapper" data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>1</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>2</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>3</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>4</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>5</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>6</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>7</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>8</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>9</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>10</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>11</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>12</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>13</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>14</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>15</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>16</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>17</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>18</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>19</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>20</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>21</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>22</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>23</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>24</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>25</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>26</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>27</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>28</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>29</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>30</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>31</span><br data-v-73cb4eb0></div></div><ul data-v-73cb4eb0><li data-v-73cb4eb0>使用替换字符串来更改原始文本的长度对于搜索来说是有效的，但是会导致不正确的高亮显示，如下例所示
<ul data-v-73cb4eb0><li data-v-73cb4eb0>此示例在遇到小写字母后跟大写字母时插入空格（即fooBarBaz→foo Bar Baz），允许单独查询camelCase单词</li></ul></li></ul> <div class="language-json line-numbers-mode" data-v-73cb4eb0><pre class="language-json" data-v-73cb4eb0><code data-v-73cb4eb0>PUT my_index
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;settings&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
    <span class="token property" data-v-73cb4eb0>&quot;analysis&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
      <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
        <span class="token property" data-v-73cb4eb0>&quot;my_analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
          <span class="token property" data-v-73cb4eb0>&quot;tokenizer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;standard&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
          <span class="token property" data-v-73cb4eb0>&quot;char_filter&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>[</span>
            <span class="token string" data-v-73cb4eb0>&quot;my_char_filter&quot;</span>
          <span class="token punctuation" data-v-73cb4eb0>]</span><span class="token punctuation" data-v-73cb4eb0>,</span>
          <span class="token property" data-v-73cb4eb0>&quot;filter&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>[</span>
            <span class="token string" data-v-73cb4eb0>&quot;lowercase&quot;</span>
          <span class="token punctuation" data-v-73cb4eb0>]</span>
        <span class="token punctuation" data-v-73cb4eb0>}</span>
      <span class="token punctuation" data-v-73cb4eb0>}</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;char_filter&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
        <span class="token property" data-v-73cb4eb0>&quot;my_char_filter&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
          <span class="token property" data-v-73cb4eb0>&quot;type&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;pattern_replace&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
          <span class="token property" data-v-73cb4eb0>&quot;pattern&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;(?&lt;=\\p{Lower})(?=\\p{Upper})&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
          <span class="token property" data-v-73cb4eb0>&quot;replacement&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot; &quot;</span>
        <span class="token punctuation" data-v-73cb4eb0>}</span>
      <span class="token punctuation" data-v-73cb4eb0>}</span>
    <span class="token punctuation" data-v-73cb4eb0>}</span>
  <span class="token punctuation" data-v-73cb4eb0>}</span><span class="token punctuation" data-v-73cb4eb0>,</span>
  <span class="token property" data-v-73cb4eb0>&quot;mappings&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
    <span class="token property" data-v-73cb4eb0>&quot;properties&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
      <span class="token property" data-v-73cb4eb0>&quot;text&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
        <span class="token property" data-v-73cb4eb0>&quot;type&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;text&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
        <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;my_analyzer&quot;</span>
      <span class="token punctuation" data-v-73cb4eb0>}</span>
    <span class="token punctuation" data-v-73cb4eb0>}</span>
  <span class="token punctuation" data-v-73cb4eb0>}</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>

POST my_index/_analyze
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;my_analyzer&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
  <span class="token property" data-v-73cb4eb0>&quot;text&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;The fooBarBaz method&quot;</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>
#结果：<span class="token punctuation" data-v-73cb4eb0>[</span> the<span class="token punctuation" data-v-73cb4eb0>,</span> foo<span class="token punctuation" data-v-73cb4eb0>,</span> bar<span class="token punctuation" data-v-73cb4eb0>,</span> baz<span class="token punctuation" data-v-73cb4eb0>,</span> method <span class="token punctuation" data-v-73cb4eb0>]</span>
</code></pre> <div class="line-numbers-wrapper" data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>1</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>2</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>3</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>4</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>5</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>6</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>7</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>8</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>9</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>10</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>11</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>12</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>13</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>14</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>15</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>16</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>17</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>18</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>19</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>20</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>21</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>22</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>23</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>24</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>25</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>26</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>27</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>28</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>29</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>30</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>31</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>32</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>33</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>34</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>35</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>36</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>37</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>38</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>39</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>40</span><br data-v-73cb4eb0></div></div><div class="language-json line-numbers-mode" data-v-73cb4eb0><pre class="language-json" data-v-73cb4eb0><code data-v-73cb4eb0>PUT my_index/_doc/<span class="token number" data-v-73cb4eb0>1</span>?refresh
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;text&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;The fooBarBaz method&quot;</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>

GET my_index/_search
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;query&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
    <span class="token property" data-v-73cb4eb0>&quot;match&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
      <span class="token property" data-v-73cb4eb0>&quot;text&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;bar&quot;</span>
    <span class="token punctuation" data-v-73cb4eb0>}</span>
  <span class="token punctuation" data-v-73cb4eb0>}</span><span class="token punctuation" data-v-73cb4eb0>,</span>
  <span class="token property" data-v-73cb4eb0>&quot;highlight&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
    <span class="token property" data-v-73cb4eb0>&quot;fields&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
      <span class="token property" data-v-73cb4eb0>&quot;text&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span><span class="token punctuation" data-v-73cb4eb0>}</span>
    <span class="token punctuation" data-v-73cb4eb0>}</span>
  <span class="token punctuation" data-v-73cb4eb0>}</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>
#高亮结果出错 Ba，因为 character filter 改变了原始文本的长度；
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;highlight&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
    <span class="token property" data-v-73cb4eb0>&quot;text&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>[</span>
      <span class="token string" data-v-73cb4eb0>&quot;The foo&lt;em&gt;Ba&lt;/em&gt;rBaz method&quot;</span> 
    <span class="token punctuation" data-v-73cb4eb0>]</span>
  <span class="token punctuation" data-v-73cb4eb0>}</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>
</code></pre> <div class="line-numbers-wrapper" data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>1</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>2</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>3</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>4</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>5</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>6</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>7</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>8</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>9</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>10</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>11</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>12</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>13</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>14</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>15</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>16</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>17</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>18</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>19</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>20</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>21</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>22</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>23</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>24</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>25</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>26</span><br data-v-73cb4eb0></div></div><br data-v-73cb4eb0> <br data-v-73cb4eb0> <h2 id="内置-tokenizer-详解" data-v-73cb4eb0><a href="#内置-tokenizer-详解" class="header-anchor" data-v-73cb4eb0>#</a> 内置 Tokenizer 详解</h2> <h3 id="_1-character-group-tokenizer" data-v-73cb4eb0><a href="#_1-character-group-tokenizer" class="header-anchor" data-v-73cb4eb0>#</a> 1. Character group tokenizer</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0>定义一个字符集合，每当遇到一个集合中的字符，<strong data-v-73cb4eb0>char_group</strong> tokenizer 就会将文本进行拆分；</li> <li data-v-73cb4eb0>它主要用于，当你想使用 pattern tokenizer 但是它的性能又比较低的时候，就可以使用 char_group tokenizer 自定义一个简单的分词器来满足类似 pattern 的需求；</li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>可选配置：</strong></li></ul> <table data-v-73cb4eb0><thead data-v-73cb4eb0><tr data-v-73cb4eb0><th data-v-73cb4eb0><strong data-v-73cb4eb0>参数</strong></th> <th data-v-73cb4eb0><strong data-v-73cb4eb0>参数说明</strong></th></tr></thead> <tbody data-v-73cb4eb0><tr data-v-73cb4eb0><td data-v-73cb4eb0>tokenize_on_chars</td> <td data-v-73cb4eb0>用作分割符的字符集合，它的值可以是单个字符(如，&quot;-&quot;)，也可以是whitesapce(&quot; &quot; or &quot;\n&quot;)，letter(a, b, ï or 京)，digit(3 or 7)，punctuation(! or &quot;)，symbol($ or √)</td></tr></tbody></table> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>举例：</strong></li></ul> <div class="language-json line-numbers-mode" data-v-73cb4eb0><pre class="language-json" data-v-73cb4eb0><code data-v-73cb4eb0>POST _analyze
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;tokenizer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
    <span class="token property" data-v-73cb4eb0>&quot;type&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;char_group&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
    <span class="token property" data-v-73cb4eb0>&quot;tokenize_on_chars&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>[</span>
      <span class="token string" data-v-73cb4eb0>&quot;whitespace&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token string" data-v-73cb4eb0>&quot;-&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token string" data-v-73cb4eb0>&quot;\n&quot;</span>
    <span class="token punctuation" data-v-73cb4eb0>]</span>
  <span class="token punctuation" data-v-73cb4eb0>}</span><span class="token punctuation" data-v-73cb4eb0>,</span>
  <span class="token property" data-v-73cb4eb0>&quot;text&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;The QUICK brown-fox&quot;</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>
#####结果：<span class="token punctuation" data-v-73cb4eb0>[</span>The<span class="token punctuation" data-v-73cb4eb0>,</span>QUICK<span class="token punctuation" data-v-73cb4eb0>,</span>brown<span class="token punctuation" data-v-73cb4eb0>,</span>fox<span class="token punctuation" data-v-73cb4eb0>]</span>
</code></pre> <div class="line-numbers-wrapper" data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>1</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>2</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>3</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>4</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>5</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>6</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>7</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>8</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>9</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>10</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>11</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>12</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>13</span><br data-v-73cb4eb0></div></div><h3 id="_2-classic-tokenizer" data-v-73cb4eb0><a href="#_2-classic-tokenizer" class="header-anchor" data-v-73cb4eb0>#</a> 2. Classic tokenizer</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>classic</strong> tokenizer，可以说是为英语而生的分词器。这个分词器对于英文的首字符缩写、 公司名字、 email 、 大部分网站域名都能很好的解决。 但是，对于英语之外的其他语言，就不是很好使。</li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>可选参数：</strong></li></ul> <table data-v-73cb4eb0><thead data-v-73cb4eb0><tr data-v-73cb4eb0><th data-v-73cb4eb0><strong data-v-73cb4eb0>参数</strong></th> <th data-v-73cb4eb0><strong data-v-73cb4eb0>参数说明</strong></th></tr></thead> <tbody data-v-73cb4eb0><tr data-v-73cb4eb0><td data-v-73cb4eb0>max_token_length</td> <td data-v-73cb4eb0>token允许的最大长度，默认255</td></tr></tbody></table> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>举例：</strong></li></ul> <div class="language-json line-numbers-mode" data-v-73cb4eb0><pre class="language-json" data-v-73cb4eb0><code data-v-73cb4eb0>PUT my_index
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;settings&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
    <span class="token property" data-v-73cb4eb0>&quot;analysis&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
      <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
        <span class="token property" data-v-73cb4eb0>&quot;my_analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
          <span class="token property" data-v-73cb4eb0>&quot;tokenizer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;my_tokenizer&quot;</span>
        <span class="token punctuation" data-v-73cb4eb0>}</span>
      <span class="token punctuation" data-v-73cb4eb0>}</span><span class="token punctuation" data-v-73cb4eb0>,</span>
      <span class="token property" data-v-73cb4eb0>&quot;tokenizer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
        <span class="token property" data-v-73cb4eb0>&quot;my_tokenizer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
          <span class="token property" data-v-73cb4eb0>&quot;type&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;classic&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
          <span class="token property" data-v-73cb4eb0>&quot;max_token_length&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token number" data-v-73cb4eb0>5</span>
        <span class="token punctuation" data-v-73cb4eb0>}</span>
      <span class="token punctuation" data-v-73cb4eb0>}</span>
    <span class="token punctuation" data-v-73cb4eb0>}</span>
  <span class="token punctuation" data-v-73cb4eb0>}</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>

POST my_index/_analyze
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;my_analyzer&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
  <span class="token property" data-v-73cb4eb0>&quot;text&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.&quot;</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>
######结果：<span class="token punctuation" data-v-73cb4eb0>[</span> The<span class="token punctuation" data-v-73cb4eb0>,</span> <span class="token number" data-v-73cb4eb0>2</span><span class="token punctuation" data-v-73cb4eb0>,</span> QUICK<span class="token punctuation" data-v-73cb4eb0>,</span> Brown<span class="token punctuation" data-v-73cb4eb0>,</span> Foxes<span class="token punctuation" data-v-73cb4eb0>,</span> jumpe<span class="token punctuation" data-v-73cb4eb0>,</span> d<span class="token punctuation" data-v-73cb4eb0>,</span> over<span class="token punctuation" data-v-73cb4eb0>,</span> the<span class="token punctuation" data-v-73cb4eb0>,</span> lazy<span class="token punctuation" data-v-73cb4eb0>,</span> dog's<span class="token punctuation" data-v-73cb4eb0>,</span> bone <span class="token punctuation" data-v-73cb4eb0>]</span>
</code></pre> <div class="line-numbers-wrapper" data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>1</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>2</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>3</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>4</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>5</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>6</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>7</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>8</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>9</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>10</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>11</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>12</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>13</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>14</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>15</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>16</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>17</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>18</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>19</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>20</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>21</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>22</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>23</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>24</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>25</span><br data-v-73cb4eb0></div></div><h3 id="_3-edge-n-gram-tokenizer" data-v-73cb4eb0><a href="#_3-edge-n-gram-tokenizer" class="header-anchor" data-v-73cb4eb0>#</a> 3. Edge n-gram tokenizer</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>edge_ngram</strong> tokenizer，会根据配置项 token_chars 中定义的指定字符集合来对文本进行拆分，然后对每个拆分后的单词进行 N-grams 处理，N-grams 处理后的 token 都是以单词的首字母作为开始；</li> <li data-v-73cb4eb0>Edge N-Grams 适用于 search-as-you-type 查询</li> <li data-v-73cb4eb0>但是当你键入的文本是类似电影名、歌曲名这类广为人知的被人熟悉的词时，completion suggester 是比 Edge N-Grams 更有效率的选择；</li> <li data-v-73cb4eb0>Edge N-Grams 处理普通单词的 autocomplete 时比较合适；</li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>可选参数：</strong></li></ul> <table data-v-73cb4eb0><thead data-v-73cb4eb0><tr data-v-73cb4eb0><th data-v-73cb4eb0><strong data-v-73cb4eb0>参数</strong></th> <th data-v-73cb4eb0><strong data-v-73cb4eb0>参数说明</strong></th></tr></thead> <tbody data-v-73cb4eb0><tr data-v-73cb4eb0><td data-v-73cb4eb0>min_gram</td> <td data-v-73cb4eb0>gram分词后允许的最小长度，默认值1</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>max_gram</td> <td data-v-73cb4eb0>gram分词后允许的最大长度，默认值2</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>token_chars</td> <td data-v-73cb4eb0>ES将会以不在字符类型所属的字符为分割符，默认值：[]，保持文本内容不变；例如，digit，会以非数字的字符作为分割符切分文本，token 中一定包含 digit；支持：<br data-v-73cb4eb0>letter —  for example a, b, ï or 京<br data-v-73cb4eb0>digit —  for example 3 or 7<br data-v-73cb4eb0>whitespace —  for example &quot; &quot; or &quot;\n&quot;<br data-v-73cb4eb0>punctuation — for example ! or &quot;<br data-v-73cb4eb0>symbol —  for example $ <br data-v-73cb4eb0>custom —  custom characters which need to be set using the custom_token_chars setting.</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>custom_token_chars</td> <td data-v-73cb4eb0><strong data-v-73cb4eb0>尚不明白用法</strong></td></tr></tbody></table> <blockquote data-v-73cb4eb0><ul data-v-73cb4eb0><li data-v-73cb4eb0>max_gram 参数的限制：
<ul data-v-73cb4eb0><li data-v-73cb4eb0>max_gram 限制了 token 的最大长度，例如 apple 做 N-Grams 处理后的词就是：[a, ap]；</li> <li data-v-73cb4eb0>如果将 edge_ngram tokenizer 作为 Index Analyzer，那么搜索关键词（如 apple）长于 max_gram 时，可能没有任何能匹配的结果；</li> <li data-v-73cb4eb0>面对上面的情况，又两种解决办法：
<ul data-v-73cb4eb0><li data-v-73cb4eb0>搜索的时候，使用 truncate token filter 作为 search analyzer，将搜索关键词（如 apple）裁剪长度到 max_gram （如 ap）；但是这种情况会返回很多不相关的结果（如 apply，snapped）;</li> <li data-v-73cb4eb0>索引的时候将 max_gram 增大，这样处理完的 token 仍会保留完整的单词（如 apple：[a,ap,app,appl,apple]），搜索的时候使用不同于索引时的 analyzer，搜索使用 standard analyzer 就可以将关键词 apple 匹配到正确的结果；</li></ul></li></ul></li></ul></blockquote> <blockquote data-v-73cb4eb0><ul data-v-73cb4eb0><li data-v-73cb4eb0>通常 ES 建议 Search Analyzer 要与 Index Analyzer 保持一致；</li> <li data-v-73cb4eb0>但是当 edge_ngram tokenizer 作为 Index Analyzer 时，情况却不同，我们的目的是在将文本切分成不完整的 token 并且索引，这样在搜索的时候，当用户输入单词字符，例如：Quick Fo，不完整的单词字符 Fo 也能作为查询条件，返回相关的结果；</li></ul></blockquote> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>举例</strong>:how to set up a field for search-as-you-type
<ul data-v-73cb4eb0><li data-v-73cb4eb0>Index Analyzer 的 max_gram 设置为10，最大可被索引的 token 是10个字符，超过10个字符的搜索关键词不会又匹配结果返回；</li></ul></li></ul> <h3 id="_4-keyword-tokenizer" data-v-73cb4eb0><a href="#_4-keyword-tokenizer" class="header-anchor" data-v-73cb4eb0>#</a> 4. Keyword tokenizer</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>keyword</strong> tokenzier，将整个文本作为一个唯一的 token；</li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>可选参数：</strong></li></ul> <table data-v-73cb4eb0><thead data-v-73cb4eb0><tr data-v-73cb4eb0><th data-v-73cb4eb0><strong data-v-73cb4eb0>参数</strong></th> <th data-v-73cb4eb0><strong data-v-73cb4eb0>参数说明</strong></th></tr></thead> <tbody data-v-73cb4eb0><tr data-v-73cb4eb0><td data-v-73cb4eb0>buffer_size</td> <td data-v-73cb4eb0>一次性读取字符到 term buffer 中的大小，默认255。当 term buffer 不够时，会自动再增长255大小，直至读完文本。建议不要更改此设置；</td></tr></tbody></table> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>举例：</strong></li></ul> <h3 id="_5-letter-tokenizer" data-v-73cb4eb0><a href="#_5-letter-tokenizer" class="header-anchor" data-v-73cb4eb0>#</a> 5. Letter tokenizer</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>letter</strong> tokenizer，遇见非单词字符的时候，就将文本进行拆分；
<ul data-v-73cb4eb0><li data-v-73cb4eb0>对欧美语系来说，它做的很合理，但是对亚洲语系来说却不友好，因为在亚洲，单词之间经常没有空格；</li></ul></li> <li data-v-73cb4eb0>没有可选参数；</li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>举例</strong>：</li></ul> <h3 id="_6-lowercase-tokenizer" data-v-73cb4eb0><a href="#_6-lowercase-tokenizer" class="header-anchor" data-v-73cb4eb0>#</a> 6. Lowercase tokenizer</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0>lowercase tokenizer，和 letter tokenizer 一样，每当遇到不是字母的字符时，都会将文本分解为 Term，但它也会将所有 Term 都小写化。</li> <li data-v-73cb4eb0>它在功能上等同于 letter tokenizer 和 lowercase token filter，但由于在一次传递中执行两个步骤，因此效率更高。</li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>没有可选参数；</strong></li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>举例：</strong></li></ul> <h3 id="_7-n-gram-tokenzier" data-v-73cb4eb0><a href="#_7-n-gram-tokenzier" class="header-anchor" data-v-73cb4eb0>#</a> 7. N-gram tokenzier</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>ngram</strong> tokenizer，遇见指定字符集合中的字符时就将文本进行拆分，然后对每个切分后的单词进行 N-grams 处理；</li> <li data-v-73cb4eb0>N-grams 就像一个滑动窗口，它在单词上移动，就像一个指定长度的连续字符序列。它们对于查询不使用空格或具有长复合词（如德语）的语言非常有用。
<ul data-v-73cb4eb0><li data-v-73cb4eb0>文本：&quot;Quick Fox&quot;；</li> <li data-v-73cb4eb0>处理结果：[ Q, Qu, u, ui, i, ic, c, ck, k, &quot;k &quot;, &quot; &quot;, &quot; F&quot;, F, Fo, o, ox, x ]</li></ul></li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>可选参数：</strong></li></ul> <table data-v-73cb4eb0><thead data-v-73cb4eb0><tr data-v-73cb4eb0><th data-v-73cb4eb0><strong data-v-73cb4eb0>参数</strong></th> <th data-v-73cb4eb0><strong data-v-73cb4eb0>参数说明</strong></th></tr></thead> <tbody data-v-73cb4eb0><tr data-v-73cb4eb0><td data-v-73cb4eb0>min_gram</td> <td data-v-73cb4eb0>gram分词后允许的最小长度，默认值1</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>max_gram</td> <td data-v-73cb4eb0>gram分词后允许的最大长度，默认值2</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>token_chars</td> <td data-v-73cb4eb0>ES将会以不在字符类型所属的字符为分割符，默认值：[]，保持文本内容不变；例如，digit，会以非数字的字符作为分割符切分文本，token 中一定包含 digit；支持：<br data-v-73cb4eb0>letter —  for example a, b, ï or 京<br data-v-73cb4eb0>digit —  for example 3 or 7<br data-v-73cb4eb0>whitespace —  for example &quot; &quot; or &quot;\n&quot;<br data-v-73cb4eb0>punctuation — for example ! or &quot;<br data-v-73cb4eb0>symbol —  for example $ <br data-v-73cb4eb0>custom —  custom characters which need to be set using the custom_token_chars setting.</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>custom_token_chars</td> <td data-v-73cb4eb0><strong data-v-73cb4eb0>尚不明白用法</strong></td></tr></tbody></table> <blockquote data-v-73cb4eb0><ul data-v-73cb4eb0><li data-v-73cb4eb0>通常建议将 min-gram 和 max_gram 设置成相同的值；</li> <li data-v-73cb4eb0>长度越小，匹配的文档越多，但匹配的质量越低。长度越长，匹配越具体。</li> <li data-v-73cb4eb0>长度可以先从3开始设置，然后进行测试调整，tri-gram (长度3) 是一个很好的开始；</li> <li data-v-73cb4eb0>Index Settings 中可通过设置 index.max_gram_diff 来控制 max_gram 与 min_gram 之间允许的最大值；</li></ul></blockquote> <ul data-v-73cb4eb0><li data-v-73cb4eb0>举例：
<ul data-v-73cb4eb0><li data-v-73cb4eb0>将字母和数字以外的字符作为分割符，并且做 tri-grams 处理，token中不满足 min_grams 的将被丢弃；</li></ul></li></ul> <h3 id="_8-path-hierarchy-tokenizer" data-v-73cb4eb0><a href="#_8-path-hierarchy-tokenizer" class="header-anchor" data-v-73cb4eb0>#</a> 8. Path hierarchy tokenizer</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0><p data-v-73cb4eb0><strong data-v-73cb4eb0>path_hierarchy</strong> tokenizer，接收一个类似文件系统路径的层次结构值，通过路径分割符拆分，将树结构中每个层级作为一个 term 输出；</p> <ul data-v-73cb4eb0><li data-v-73cb4eb0>文本：&quot;/one/two/three&quot;；</li> <li data-v-73cb4eb0>处理结果：[ /one, /one/two, /one/two/three ]；</li> <li data-v-73cb4eb0>最终输出的 token 一定是树状结构中的某一个部分值；</li></ul></li> <li data-v-73cb4eb0><p data-v-73cb4eb0><strong data-v-73cb4eb0>可选参数：</strong></p></li></ul> <table data-v-73cb4eb0><thead data-v-73cb4eb0><tr data-v-73cb4eb0><th data-v-73cb4eb0><strong data-v-73cb4eb0>参数</strong></th> <th data-v-73cb4eb0><strong data-v-73cb4eb0>参数说明</strong></th></tr></thead> <tbody data-v-73cb4eb0><tr data-v-73cb4eb0><td data-v-73cb4eb0>delimiter</td> <td data-v-73cb4eb0>路径分割符，默认 &quot;/&quot;</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>replacement</td> <td data-v-73cb4eb0>用于 delimiter 的可选替换字符。默认为 delimiter</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>buffer_size</td> <td data-v-73cb4eb0>一次传递中读入 term buffer 的字符数，默认1024，term buffer 将按此大小增长，直到所有文本都被读完。建议不要更改此设置</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>reverse</td> <td data-v-73cb4eb0>如果设置为 true，则以相反的顺序输出 token，默认为false（注意参考举例：正常层级数的[123]，reverse后[321]）</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>skip</td> <td data-v-73cb4eb0>要跳过的初始 token，默认为0。</td></tr></tbody></table> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>举例：</strong> <ul data-v-73cb4eb0><li data-v-73cb4eb0>分割符使用 &quot;-&quot;，且最后 term 中用 &quot;/&quot; 替换 &quot;-&quot;，且前两个初始 token 丢弃不要；</li> <li data-v-73cb4eb0>对 file_path 路径字段在索引时，使用两个自定义的 path_hierarchy tokenizer，path token 生成分别是 forward 和 reverse；</li> <li data-v-73cb4eb0>path_hierarchy tokenizer，forward 和 reverse 效果比较：</li></ul></li></ul> <h3 id="_9-pattern-tokenizer" data-v-73cb4eb0><a href="#_9-pattern-tokenizer" class="header-anchor" data-v-73cb4eb0>#</a> 9. Pattern tokenizer</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>pattern</strong> tokenizer，使用正则表达式在匹配到分割符时拆分文本，或者将匹配到的文本捕获为 terms；</li> <li data-v-73cb4eb0>默认的匹配表达式是 \W+，遇到非单词时拆分文本；</li> <li data-v-73cb4eb0>pattern tokenizer 使用 Java 正则表达式；</li> <li data-v-73cb4eb0>写得不好的正则表达式可能运行的非常慢，甚至会抛出 StackOverflowError 并导致运行它的节点崩溃；</li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>可选参数：</strong></li></ul> <table data-v-73cb4eb0><thead data-v-73cb4eb0><tr data-v-73cb4eb0><th data-v-73cb4eb0><strong data-v-73cb4eb0>参数</strong></th> <th data-v-73cb4eb0><strong data-v-73cb4eb0>参数说明</strong></th></tr></thead> <tbody data-v-73cb4eb0><tr data-v-73cb4eb0><td data-v-73cb4eb0>pattern</td> <td data-v-73cb4eb0>Java正则表达式，默认 \W+</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>flags</td> <td data-v-73cb4eb0>Java正则中的 flags，可以多个值，但是要用管道符 &quot;|&quot; 来分隔</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>group</td> <td data-v-73cb4eb0>哪个 group 去抽取数据。 默认是 to -1 (用pattern作为分割符去split).</td></tr></tbody></table> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>flags 参数的取值说明：</strong></li></ul> <table data-v-73cb4eb0><thead data-v-73cb4eb0><tr data-v-73cb4eb0><th data-v-73cb4eb0><strong data-v-73cb4eb0>编译标志</strong></th> <th data-v-73cb4eb0><strong data-v-73cb4eb0>效果</strong></th></tr></thead> <tbody data-v-73cb4eb0><tr data-v-73cb4eb0><td data-v-73cb4eb0>Pattern.CANON_EQ</td> <td data-v-73cb4eb0>当且仅当两个字符的&quot;正规分解(canonical decomposition)&quot;都完全相同的情况下，才认定匹配。比如用了这个标志之后，表达式&quot;a/u030A&quot;会匹配&quot;?&quot;。默认情况下，不考虑&quot;规范相等性(canonical equivalence)&quot;。</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>Pattern.CASE_INSENSITIVE (?i)</td> <td data-v-73cb4eb0>默认情况下，大小写不明感的匹配只适用于US-ASCII字符集。这个标志能让表达式忽略大小写进行匹配。要想对Unicode字符进行大小不明感的匹配，只要将UNICODE_CASE与这个标志合起来就行了。</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>Pattern.COMMENTS (?x)</td> <td data-v-73cb4eb0>在这种模式下，匹配时会忽略(正则表达式里的)空格字符(注：不是指表达式里的&quot;//s&quot;，而是指表达式里的空格，tab，回车之类)。注释从#开始，一直到这行结束。可以通过嵌入式的标志来启用Unix行模式。</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>Pattern.DOTALL (?s)</td> <td data-v-73cb4eb0>在这种模式下，表达式'.'可以匹配任意字符，包括表示一行的结束符。默认情况下，表达式'.'不匹配行的结束符。</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>Pattern.MULTILINE (?m)</td> <td data-v-73cb4eb0>在这种模式下，'^'和'$'分别匹配一行的开始和结束。此外，'^'仍然匹配字符串的开始，'$'也匹配字符串的结束。默认情况下，这两个表达式仅仅匹配字符串的开始和结束。</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>Pattern.UNICODE_CASE (?u)</td> <td data-v-73cb4eb0>在这个模式下，如果你还启用了CASE_INSENSITIVE标志，那么它会对Unicode字符进行大小写不明感的匹配。默认情况下，大小写不明感的匹配只适用于US-ASCII字符集。</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>Pattern.UNIX_LINES (?d)</td> <td data-v-73cb4eb0>在这个模式下，只有'/n'才被认作一行的中止，并且与'.'，'^'，以及'$'进行匹配。</td></tr></tbody></table> <ul data-v-73cb4eb0><li data-v-73cb4eb0><p data-v-73cb4eb0><strong data-v-73cb4eb0>group 捕获组参数说明：</strong></p> <ul data-v-73cb4eb0><li data-v-73cb4eb0>普通捕获组（Expression）：从正则表达式左侧开始，每出现一个左括号&quot;(&quot;记做一个分组，分组编号从 1 开始。0 代表整个表达式。例如：对于时间字符串：2017-04-25，表达式如下 (\d{4})-((\d{2})-(\d{2}))
<ul data-v-73cb4eb0><li data-v-73cb4eb0>group(0)，捕获组 (\d{4})-((\d{2})-(\d{2}))，匹配 2017-04-25；</li> <li data-v-73cb4eb0>group(1)，捕获组 (\d{4})，匹配 2017；</li> <li data-v-73cb4eb0>group(2)，捕获组 ((\d{2})-(\d{2}))，匹配 04-25；</li> <li data-v-73cb4eb0>group(3)，捕获组 (\d{2})，匹配 04；</li> <li data-v-73cb4eb0>group(4)，捕获组 (\d{2})，匹配 25；</li></ul></li> <li data-v-73cb4eb0>命名捕获组（?Expression）：每个以左括号开始的捕获组，都紧跟着 ?，而后才是正则表达式。例如：对于时间字符串：2017-04-25，表达式如下 <code data-v-73cb4eb0>(?&lt;\year&gt;\\d{4})-(?&lt;\md&gt;(?&lt;\month&gt;\\d{2})-(?&lt;\date&gt;\\d{2}))</code> <ul data-v-73cb4eb0><li data-v-73cb4eb0>group(0)，捕获组 (\d{4})-((\d{2})-(\d{2}))，匹配 2017-04-25；</li> <li data-v-73cb4eb0>group(&quot;year&quot;)，捕获组 (\d{4})，匹配 2017；</li> <li data-v-73cb4eb0>group(&quot;md&quot;)，捕获组 ((\d{2})-(\d{2}))，匹配 04-25；</li> <li data-v-73cb4eb0>group(&quot;month&quot;)，捕获组 (\d{2})，匹配 04；</li> <li data-v-73cb4eb0>group(&quot;date&quot;)，捕获组 (\d{2})，匹配 25；</li> <li data-v-73cb4eb0>命名的捕获组同样也可以使用编号获取相应值。</li></ul></li> <li data-v-73cb4eb0>非捕获组（?:Expression）：在左括号后紧跟 ?:，而后再加上正则表达式。例如：对于时间字符串：2017-04-25，表达式如下 (?:\d{4})-((\d{2})-(\d{2}))
<ul data-v-73cb4eb0><li data-v-73cb4eb0>group(0)，捕获组 (\d{4})-((\d{2})-(\d{2}))，匹配 2017-04-25；</li> <li data-v-73cb4eb0>group(1)，捕获组 ((\d{2})-(\d{2}))，匹配 04-25；</li> <li data-v-73cb4eb0>group(2)，捕获组 (\d{2})，匹配 04；</li> <li data-v-73cb4eb0>group(3)，捕获组 (\d{2})，匹配 25；</li> <li data-v-73cb4eb0>这个正则表达式虽然有四个左括号，理论上有 4 个捕获组。但是第一组 (?:\d{4})，其实是被忽略的。当使用 matcher.group(4) 时，系统会报错 IndexOutOfBoundsException。</li></ul></li></ul></li> <li data-v-73cb4eb0><p data-v-73cb4eb0><strong data-v-73cb4eb0>举例：</strong></p> <ul data-v-73cb4eb0><li data-v-73cb4eb0>正则表达式：通过 pattern 去捕获双引号内的文本，但是忽略文本中的引号，仅仅将它当作一个引号字符；</li> <li data-v-73cb4eb0>注意：在 JSON 中写 pattern 正则表达式，&quot; 和 \ 字符都需要转义；</li></ul></li></ul> <h3 id="_10-simple-pattern-tokenizer" data-v-73cb4eb0><a href="#_10-simple-pattern-tokenizer" class="header-anchor" data-v-73cb4eb0>#</a> 10. Simple pattern tokenizer</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>simple_pattern</strong> tokenizer，使用正则表达式来捕获匹配的文本作为 terms。它支持的正则表达式比 pattern tokenizer 更有限，但是 simple_pattern 通常更快；</li> <li data-v-73cb4eb0>simple_pattern 的 pattern 的只能用来捕获文本生成 terms，不能像 pattern tokenizer 支持用 pattern 作为分割符去分割文本；</li> <li data-v-73cb4eb0>使用 Lucene 正则表达式；</li> <li data-v-73cb4eb0>默认 pattern 是空字符串，它不生成任何 terms。所以 simple_pattern 应该使用非默认 pattern；</li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>可选参数：</strong></li></ul> <table data-v-73cb4eb0><thead data-v-73cb4eb0><tr data-v-73cb4eb0><th data-v-73cb4eb0><strong data-v-73cb4eb0>参数</strong></th> <th data-v-73cb4eb0><strong data-v-73cb4eb0>参数说明</strong></th></tr></thead> <tbody data-v-73cb4eb0><tr data-v-73cb4eb0><td data-v-73cb4eb0>pattern</td> <td data-v-73cb4eb0>Lucene正则表达式，默认空字符串</td></tr></tbody></table> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>举例：</strong></li></ul> <h3 id="_11-simple-pattern-split-tokenizer" data-v-73cb4eb0><a href="#_11-simple-pattern-split-tokenizer" class="header-anchor" data-v-73cb4eb0>#</a> 11. Simple pattern split tokenizer</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>simple_pattern_split</strong> tokenizer，使用正则表达式将匹配到的内容作为分割符对文本进行拆分；
<ul data-v-73cb4eb0><li data-v-73cb4eb0>比 pattern tokenizer 支持的正则更有限，但是更快；</li></ul></li> <li data-v-73cb4eb0>使用 Lucene 正则表达式；</li> <li data-v-73cb4eb0>默认 pattern 是空字符串，它将整个文本作为 term，使用的时候不要使用默认pattern；</li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>可选参数：</strong></li></ul> <table data-v-73cb4eb0><thead data-v-73cb4eb0><tr data-v-73cb4eb0><th data-v-73cb4eb0><strong data-v-73cb4eb0>参数</strong></th> <th data-v-73cb4eb0><strong data-v-73cb4eb0>参数说明</strong></th></tr></thead> <tbody data-v-73cb4eb0><tr data-v-73cb4eb0><td data-v-73cb4eb0>pattern</td> <td data-v-73cb4eb0>Lucene正则表达式，默认空字符串</td></tr></tbody></table> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>举例：</strong></li></ul> <h3 id="_12-standard-tokenizer" data-v-73cb4eb0><a href="#_12-standard-tokenizer" class="header-anchor" data-v-73cb4eb0>#</a> 12. Standard tokenizer</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>standard</strong> tokenizer，提供了基于语法的拆分文本（基于Unicode文本分割算法），并且适用于大多数语言。</li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>可选参数：</strong></li></ul> <table data-v-73cb4eb0><thead data-v-73cb4eb0><tr data-v-73cb4eb0><th data-v-73cb4eb0><strong data-v-73cb4eb0>参数</strong></th> <th data-v-73cb4eb0><strong data-v-73cb4eb0>参数说明</strong></th></tr></thead> <tbody data-v-73cb4eb0><tr data-v-73cb4eb0><td data-v-73cb4eb0>max_token_length</td> <td data-v-73cb4eb0>token允许的最大长度，如果超过了就按照max_token_length拆分它，默认255</td></tr></tbody></table> <ul data-v-73cb4eb0><li data-v-73cb4eb0>举例：</li></ul> <h3 id="_13-thai-tokenizer" data-v-73cb4eb0><a href="#_13-thai-tokenizer" class="header-anchor" data-v-73cb4eb0>#</a> 13. Thai tokenizer</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>thai</strong> tokenizer，用 Java 附带的泰语分段算法将泰语文本分割成单词。一般来说，其他语言中的文本处理将与 standard tokenizer 相同。</li> <li data-v-73cb4eb0>注意：并非所有的 JRE 都支持它，但是可以与 Sun/Oracle 和 OpenJDK 一起工作；</li> <li data-v-73cb4eb0>如果想要程序应用可完全移植，可以使用 ICU tokenizer（不是内置的）；</li> <li data-v-73cb4eb0>没有可选参数；</li></ul> <h3 id="_14-uax-url-email-tokenzier" data-v-73cb4eb0><a href="#_14-uax-url-email-tokenzier" class="header-anchor" data-v-73cb4eb0>#</a> 14. UAX URL email tokenzier</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>uax_url_email</strong> tokenizer，与 standard tokenizer 类似，只是它将 url 和电子邮件地址识别为单个 token。</li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>可选参数：</strong></li></ul> <table data-v-73cb4eb0><thead data-v-73cb4eb0><tr data-v-73cb4eb0><th data-v-73cb4eb0><strong data-v-73cb4eb0>参数</strong></th> <th data-v-73cb4eb0><strong data-v-73cb4eb0>参数说明</strong></th></tr></thead> <tbody data-v-73cb4eb0><tr data-v-73cb4eb0><td data-v-73cb4eb0>max_token_length</td> <td data-v-73cb4eb0>token允许的最大长度，如果超过了就按照max_token_length拆分它，默认255</td></tr></tbody></table> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>举例：</strong></li></ul> <h3 id="_15-whitespace-tokenizer" data-v-73cb4eb0><a href="#_15-whitespace-tokenizer" class="header-anchor" data-v-73cb4eb0>#</a> 15. Whitespace tokenizer</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0>whitespace tokenizer，遇到空格时对文本进行拆分；</li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>可选参数：</strong></li></ul> <table data-v-73cb4eb0><thead data-v-73cb4eb0><tr data-v-73cb4eb0><th data-v-73cb4eb0><strong data-v-73cb4eb0>参数</strong></th> <th data-v-73cb4eb0><strong data-v-73cb4eb0>参数说明</strong></th></tr></thead> <tbody data-v-73cb4eb0><tr data-v-73cb4eb0><td data-v-73cb4eb0>max_token_length</td> <td data-v-73cb4eb0>token允许的最大长度，如果超过了就按照max_token_length拆分它，默认255</td></tr></tbody></table> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>举例：</strong></li></ul> <br data-v-73cb4eb0> <br data-v-73cb4eb0> <h2 id="内置-token-filter-详解" data-v-73cb4eb0><a href="#内置-token-filter-详解" class="header-anchor" data-v-73cb4eb0>#</a> 内置 Token filter 详解</h2> <p data-v-73cb4eb0>Tokenzier Filter 可以从 Tokenizer 接收 token stream，并且可以修改 token（如小写化），删除 token（如去除stopwords），添加 token（如同义词）；</p> <h3 id="_1-apostrophe-token-filter" data-v-73cb4eb0><a href="#_1-apostrophe-token-filter" class="header-anchor" data-v-73cb4eb0>#</a> 1. Apostrophe token filter</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>apostrophe</strong> 可以将撇号后面的内容全部去掉，包括撇号本身；</li></ul> <div class="language-json line-numbers-mode" data-v-73cb4eb0><pre class="language-json" data-v-73cb4eb0><code data-v-73cb4eb0>GET /_analyze
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;tokenizer&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;standard&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
  <span class="token property" data-v-73cb4eb0>&quot;filter&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>[</span><span class="token string" data-v-73cb4eb0>&quot;apostrophe&quot;</span><span class="token punctuation" data-v-73cb4eb0>]</span><span class="token punctuation" data-v-73cb4eb0>,</span>
  <span class="token property" data-v-73cb4eb0>&quot;text&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;Istanbul'a veya Istanbul'dan&quot;</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>
#token stream：<span class="token punctuation" data-v-73cb4eb0>[</span>Istanbul'a<span class="token punctuation" data-v-73cb4eb0>,</span> veya<span class="token punctuation" data-v-73cb4eb0>,</span> Istanbul'dan<span class="token punctuation" data-v-73cb4eb0>]</span>
#结果：<span class="token punctuation" data-v-73cb4eb0>[</span> Istanbul<span class="token punctuation" data-v-73cb4eb0>,</span> veya<span class="token punctuation" data-v-73cb4eb0>,</span> Istanbul <span class="token punctuation" data-v-73cb4eb0>]</span>

#自定义 Analyzer
PUT /apostrophe_example
<span class="token punctuation" data-v-73cb4eb0>{</span>
    <span class="token property" data-v-73cb4eb0>&quot;settings&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
        <span class="token property" data-v-73cb4eb0>&quot;analysis&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
            <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
                <span class="token property" data-v-73cb4eb0>&quot;standard_apostrophe&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
                    <span class="token property" data-v-73cb4eb0>&quot;tokenizer&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;standard&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
                    <span class="token property" data-v-73cb4eb0>&quot;filter&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>[</span><span class="token string" data-v-73cb4eb0>&quot;apostrophe&quot;</span><span class="token punctuation" data-v-73cb4eb0>]</span>
                <span class="token punctuation" data-v-73cb4eb0>}</span>
            <span class="token punctuation" data-v-73cb4eb0>}</span>
        <span class="token punctuation" data-v-73cb4eb0>}</span>
    <span class="token punctuation" data-v-73cb4eb0>}</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>
</code></pre> <div class="line-numbers-wrapper" data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>1</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>2</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>3</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>4</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>5</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>6</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>7</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>8</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>9</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>10</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>11</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>12</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>13</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>14</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>15</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>16</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>17</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>18</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>19</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>20</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>21</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>22</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>23</span><br data-v-73cb4eb0></div></div><h3 id="_2-ascii-folding-token-filter" data-v-73cb4eb0><a href="#_2-ascii-folding-token-filter" class="header-anchor" data-v-73cb4eb0>#</a> 2. ASCII folding token filter</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>asciifolding</strong>，将不在 Basic Latin Unicode（前127个 ASCII 字符）中的字母、数字和符号字符转换为其等效的ASCII（如果存在）。例如，过滤器将 à 更改为 a。</li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>可选参数：</strong></li></ul> <table data-v-73cb4eb0><thead data-v-73cb4eb0><tr data-v-73cb4eb0><th data-v-73cb4eb0><strong data-v-73cb4eb0>参数</strong></th> <th data-v-73cb4eb0><strong data-v-73cb4eb0>参数说明</strong></th></tr></thead> <tbody data-v-73cb4eb0><tr data-v-73cb4eb0><td data-v-73cb4eb0>preserve_original</td> <td data-v-73cb4eb0>（可选，布尔值）如果为true，则同时发出原始token和处理后的token。默认为false。</td></tr></tbody></table> <div class="language-json line-numbers-mode" data-v-73cb4eb0><pre class="language-json" data-v-73cb4eb0><code data-v-73cb4eb0>PUT /asciifold_example
<span class="token punctuation" data-v-73cb4eb0>{</span>
    <span class="token property" data-v-73cb4eb0>&quot;settings&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
        <span class="token property" data-v-73cb4eb0>&quot;analysis&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
            <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
                <span class="token property" data-v-73cb4eb0>&quot;standard_asciifolding&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
                    <span class="token property" data-v-73cb4eb0>&quot;tokenizer&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;standard&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
                    <span class="token property" data-v-73cb4eb0>&quot;filter&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>[</span><span class="token string" data-v-73cb4eb0>&quot;my_ascii_folding&quot;</span><span class="token punctuation" data-v-73cb4eb0>]</span>
                <span class="token punctuation" data-v-73cb4eb0>}</span>
            <span class="token punctuation" data-v-73cb4eb0>}</span><span class="token punctuation" data-v-73cb4eb0>,</span>
            <span class="token property" data-v-73cb4eb0>&quot;filter&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
                <span class="token property" data-v-73cb4eb0>&quot;my_ascii_folding&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token punctuation" data-v-73cb4eb0>{</span>
                    <span class="token property" data-v-73cb4eb0>&quot;type&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;asciifolding&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
                    <span class="token property" data-v-73cb4eb0>&quot;preserve_original&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token boolean" data-v-73cb4eb0>true</span>
                <span class="token punctuation" data-v-73cb4eb0>}</span>
            <span class="token punctuation" data-v-73cb4eb0>}</span>
        <span class="token punctuation" data-v-73cb4eb0>}</span>
    <span class="token punctuation" data-v-73cb4eb0>}</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>
#测试
GET asciifold_example/_analyze
<span class="token punctuation" data-v-73cb4eb0>{</span>
  <span class="token property" data-v-73cb4eb0>&quot;analyzer&quot;</span><span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;standard_asciifolding&quot;</span><span class="token punctuation" data-v-73cb4eb0>,</span>
  <span class="token property" data-v-73cb4eb0>&quot;text&quot;</span> <span class="token operator" data-v-73cb4eb0>:</span> <span class="token string" data-v-73cb4eb0>&quot;açaí à la carte&quot;</span>
<span class="token punctuation" data-v-73cb4eb0>}</span>
#结果：<span class="token punctuation" data-v-73cb4eb0>[</span> acai<span class="token punctuation" data-v-73cb4eb0>,</span> açaí<span class="token punctuation" data-v-73cb4eb0>,</span> a<span class="token punctuation" data-v-73cb4eb0>,</span> à<span class="token punctuation" data-v-73cb4eb0>,</span> la<span class="token punctuation" data-v-73cb4eb0>,</span> carte <span class="token punctuation" data-v-73cb4eb0>]</span>
</code></pre> <div class="line-numbers-wrapper" data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>1</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>2</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>3</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>4</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>5</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>6</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>7</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>8</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>9</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>10</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>11</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>12</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>13</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>14</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>15</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>16</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>17</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>18</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>19</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>20</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>21</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>22</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>23</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>24</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>25</span><br data-v-73cb4eb0><span class="line-number" data-v-73cb4eb0>26</span><br data-v-73cb4eb0></div></div><h3 id="_3-cjk-bigram-token-filter" data-v-73cb4eb0><a href="#_3-cjk-bigram-token-filter" class="header-anchor" data-v-73cb4eb0>#</a> 3. CJK bigram token filter</h3> <ul data-v-73cb4eb0><li data-v-73cb4eb0><strong data-v-73cb4eb0>cjk_bigram</strong>，适用于 CJK（中文、日语和韩语）token，在内置的 CJK analyzer 中被使用；</li> <li data-v-73cb4eb0><strong data-v-73cb4eb0>可选参数：</strong></li></ul> <table data-v-73cb4eb0><thead data-v-73cb4eb0><tr data-v-73cb4eb0><th data-v-73cb4eb0><strong data-v-73cb4eb0>参数</strong></th> <th data-v-73cb4eb0><strong data-v-73cb4eb0>参数说明</strong></th></tr></thead> <tbody data-v-73cb4eb0><tr data-v-73cb4eb0><td data-v-73cb4eb0>ignored_scripts</td> <td data-v-73cb4eb0>（可选，字符数组）要禁用bigram的字符串数组。可能值：han（汉）hangul（朝鲜文）hiragana（平假名）katakana（片假名）所有非CJK的字符单词都不做修改处理；</td></tr> <tr data-v-73cb4eb0><td data-v-73cb4eb0>output_unigrams</td> <td data-v-73cb4eb0>（可选，boolean）如果为true，则以bigram和unigram形式发出token。如果为false，则当没有相邻字符时，将以unigram形式输出CJK字符。默认为false。</td></tr></tbody></table></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/BigDataAndDistributedSystem/ELK/ESIndex-IndexTemplate.html" class="prev">ES Index-Index Template</a></span> <span class="next"><a href="/BigDataAndDistributedSystem/ELK/ESIndex-IngestAndScript.html">ES Index-Ingest|Script</a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.29af2d6c.js" defer></script><script src="/assets/js/2.858e58ff.js" defer></script><script src="/assets/js/62.64d7637a.js" defer></script>
  </body>
</html>
